{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "477d1bc5-5366-4ae3-afa7-84c3e75142cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def introspect(obj):\n",
    "  for func in [type, id, dir, vars, callable]:\n",
    "        print(\"%s(%s):\\t\\t%s\" % (func.__name__, introspect.__code__.co_varnames[0], func(obj)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfed32ff-d098-4bd8-afbf-54dcb42226db",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4148929012.py, line 172)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [2]\u001b[0;36m\u001b[0m\n\u001b[0;31m    else\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import hashlib\n",
    "import os\n",
    "from datetime import datetime as datingdays\n",
    "import time\n",
    "from pytz import timezone\n",
    "from git import Repo, Git\n",
    "import sys\n",
    "import threading\n",
    "project_root_path = '../../..'\n",
    "python_lib_path = project_root_path + '/python/lib'\n",
    "sys.path.append(python_lib_path)\n",
    "from commit_log_parser import NumstatRequirementSet\n",
    "from os.path import exists\n",
    "        \n",
    "def loadCachedURL(url, forceReload = False):\n",
    "    body = None\n",
    "    hl = hashlib.new('sha256')\n",
    "    ba = bytearray(url.encode())\n",
    "    hl.update(ba)\n",
    "    thing = hl.hexdigest()\n",
    "    cachedFileName = './'+thing\n",
    "    loaded = False;\n",
    "    if not forceReload:\n",
    "        try:\n",
    "            with open(cachedFileName, 'r') as f:\n",
    "                body = json.load(f)\n",
    "                f.close()\n",
    "            loaded = True\n",
    "        except EnvironmentError:\n",
    "            pass\n",
    "\n",
    "    if not loaded:\n",
    "        resp = requests.get(url)\n",
    "        if (resp.status_code == 200):\n",
    "            body = resp.json()\n",
    "            with open(cachedFileName, 'w') as f:\n",
    "                f.write(resp.text)\n",
    "                f.close()\n",
    "    return body\n",
    "class Commit:\n",
    "    sha = None\n",
    "    date = None\n",
    "    hacker = None\n",
    "class RepoName:\n",
    "    def key(self):\n",
    "        return self.owner+'/'+self.repo_name\n",
    "    def __init__(self, owner, repo_name):\n",
    "        self.owner = owner\n",
    "        self.repo_name = repo_name\n",
    "    \n",
    "class Hacker:\n",
    "    def toJSON(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, \n",
    "            sort_keys=True, indent=2)    \n",
    "    def __init__(self):\n",
    "        self.user_id = None\n",
    "        self.commits = []\n",
    "        self.aliases = Counter()\n",
    "    def __init__(self, user_id):\n",
    "        self.user_id = user_id;\n",
    "class Repository:\n",
    "    def __init__(self, repo_id, repo_name):\n",
    "        self.repo_id = repo_id\n",
    "        self.repo_name = repo_name\n",
    "class MyCounter:\n",
    "    def __init__(self, init_val):\n",
    "        self.counter = init_val\n",
    "    def __init__(self):\n",
    "        self.__init__(0)\n",
    "    def increment(self):\n",
    "        self.count += 1\n",
    "    def val(self):\n",
    "        return self.counter\n",
    "    \n",
    "# Types of queries:\n",
    "#\n",
    "#  Single query to derive a user ID\n",
    "#  Mass commit log\n",
    "class Query:\n",
    "    def __init__(self):\n",
    "        self.MAX_LOOPS = 5\n",
    "        self.urlPrefix = 'https://api.github.com/search/commits'\n",
    "        self.startDate = datingdays.now(timezone('US/Arizona'))\n",
    "        self.hackers = {}\n",
    "        self.repos = {}\n",
    "        self.aliases = {}\n",
    "        self.resolved_alias_map = {}\n",
    "        self.commit_to_repo_map = {}\n",
    "        self.json_repo_map = {}\n",
    "        self.commit_cache_map = {}\n",
    "        self.thread = threading.Thread(target=self.monitor_alias, daemon=True)\n",
    "        self.thread.daemon = True\n",
    "        self.thread.start()\n",
    "        with open('./web3.github.token', 'r') as f:\n",
    "            self.token = f.readline()\n",
    "            self.token = self.token.strip('\\n')\n",
    "            self.headers = {'Authorization': 'token %s' % self.token}\n",
    "    def add_alias(self, alias, commit_key):\n",
    "        if (alias not in self.aliases.keys()):\n",
    "            self.aliases[alias] = []\n",
    "        self.aliases[alias].append(commit_key)\n",
    "    \n",
    "    def reset_last_date(self):\n",
    "        self.startDate = datingdays.now(timezone('US/Arizona'))\n",
    "    def set_last_date(self, date):\n",
    "        new_date = self.startDate\n",
    "        if date.endswith('Z'):\n",
    "            date = date[:len(date)-2]\n",
    "        try:\n",
    "            new_date = datingdays.fromisoformat(date)\n",
    "            if (new_date < self.startDate):\n",
    "    #           Note: GitHub rejected dates with timezones other than \"-07:00\" (like \"+02:00\")\n",
    "    #                 By subtracting the difference (in milliseconds?) we represent the \"US/Arizona\"\n",
    "    #                 version of the author-date pulled from previous results\n",
    "                self.startDate = self.startDate - (self.startDate - new_date)\n",
    "        except:\n",
    "            #Skip a bit, brother.\n",
    "            #Even if this is the very last commit in this set\n",
    "            # it may be repeated at the beginning of the next\n",
    "            # query, but won't cause an endless loop. If it's the last\n",
    "            # commit in the whole set for a particular hacker it will\n",
    "            # still exit the loop due to a < 100 item result set.\n",
    "            pass\n",
    "    def format_user_url(self, user_id):\n",
    "        var = self.urlPrefix+\"?q=author:\"+user_id+'+author-date:<'+self.startDate.isoformat()+'&sort=author-date&order=desc&per_page=100&page=1'\n",
    "        print(var)\n",
    "        return var\n",
    "    def load_hacker_url(self, user_id, recurse_count=1):\n",
    "        retVal = None\n",
    "        resp = requests.get(self.format_user_url(user_id), headers=self.headers)\n",
    "        if (resp.status_code == 200):\n",
    "            retVal = resp.json()\n",
    "        elif (resp.status_code == 403):\n",
    "            print('Rate limit EXCEEDED.  Sleeping for a bit. (recursive_count=', recurse_count,')')\n",
    "            time.sleep(recurse_count * 60)\n",
    "            return self.load_hacker_url(user_id, recurse_count+1)\n",
    "        else:\n",
    "            print('Status code returned:', resp.status_code)\n",
    "            req_headers = resp.request.headers\n",
    "            for n in req_headers.keys():\n",
    "                print('\\t', n, req_headers[n])\n",
    "            print(json.dumps(resp.json(), indent=2))\n",
    "        return retVal\n",
    "    def load_file(self, file_name):\n",
    "        ret_val = {}\n",
    "        if (exists(file_name)):\n",
    "            with open(file_name, 'r') as af:\n",
    "                ret_val = json.load(af)\n",
    "        return ret_val\n",
    "    def preload_alias_maps(self):\n",
    "        self.resolve_alias_map = self.load_file('./aliasMap.json')\n",
    "        self.hackers = self.load_file('./hackers.json')\n",
    "        \n",
    "    def add_commit_id(self, commit_id, repo_name):\n",
    "        self.commit_to_repo_map[commit_id] = repo_name\n",
    "    def format_id_check_url(self, commit_id):\n",
    "        rn = self.commit_to_repo_map[commit_id]\n",
    "        return 'https://api.github.com/repos/'+rn.owner+'/'+rn.repo_name+'/commits/'+commit_id\n",
    "    def retrieve_commit(self, commit_hash, recurse_count=1):\n",
    "        url = self.format_id_check_url(commit_hash)\n",
    "        resp = requests.get(self.format_id_check_url(commit_hash), headers=self.headers)\n",
    "        if (resp.status_code == 422):\n",
    "            print('ERROR - Status code:', resp.status_code, 'encountered ', url)\n",
    "            return None\n",
    "        elif resp.status_code == 403:\n",
    "            ##We've exceed our 5000 calls per hour!\n",
    "            print('Maximum calls/hour exceeded! Sleeping ', recurse_count, 'minute(s)')\n",
    "            time.sleep(60*recurse_count)\n",
    "            if recurse_count <= this.MAX_LOOPS:\n",
    "                return self.retrieve_commit(commit_hash, recurse_count+1)\n",
    "            else:\n",
    "                return None\n",
    "        elif resp.status_code == 200:            \n",
    "            return resp\n",
    "\n",
    "    def stop_monitor(self):\n",
    "        self.monitor_running = False\n",
    "    def monitor_alias(self):\n",
    "        self.monitor_running = True\n",
    "        while self.monitor_running:\n",
    "            try:\n",
    "                time.sleep(10)\n",
    "                print(len(self.hackers), 'root level hackers resolved')\n",
    "            except:\n",
    "                print('Unexpected error occurred - Leaving')\n",
    "                self.monitor_running = False\n",
    "                \n",
    "    def process_commit_response(self, resp, sha_array, alias, recursive_count=0):\n",
    "        j = resp.json()\n",
    "        commit_details_block = j['author']\n",
    "        if (commit_details_block == None):\n",
    "            commit_details_block = j['committer']\n",
    "        if (commit_details_block == None):\n",
    "            if recursive_count < self.MAX_LOOPS and recursive_count < (len(sha_array)-1):\n",
    "                old_hash = sha_array[recursive_count]\n",
    "                recursive_count += 1\n",
    "                new_hash = sha_array[recursive_count]\n",
    "                self.commit_to_repo_map[new_hash] = self.commit_to_repo_map[old_hash]\n",
    "                resp = self.retrieve_commit(new_hash)\n",
    "                if (resp is not None):\n",
    "                    self.process_commit_response(resp, sha_array, alias, recursive_count)\n",
    "            else:\n",
    "                print('Unable to find author node within JSON formatted result set', alias)\n",
    "        else:\n",
    "            if 'login' in commit_details_block.keys():                \n",
    "                committer = commit_details_block['login']\n",
    "                if (committer not in self.hackers.keys()):\n",
    "                    #print('Creating new hacker object for '+committer+' ['+alias+']')\n",
    "                    self.hackers[committer] = []\n",
    "                self.hackers[committer].append(alias)\n",
    "                self.resolved_alias_map[alias] = committer\n",
    "            else:\n",
    "                print('Cannot find login key', json.dumps(j, indent=2))\n",
    "        \n",
    "    def resolve_aliases(self):\n",
    "        #threading.Thread(target=self.monitor_alias, args=(self,))\n",
    "        for alias in self.aliases.keys():\n",
    "            if alias not in self.resolved_alias_map.keys():\n",
    "                commit_id = q.aliases[alias][0]  #Lookup just the first one\n",
    "                #print('Resolving ['+alias+'] using commit ID: '+commit_id)\n",
    "                resp = self.retrieve_commit(commit_id)\n",
    "                if (resp != None):\n",
    "                    self.process_commit_response(resp, q.aliases[alias], alias)\n",
    "class RepoCounter:\n",
    "    def __init__(self, repo_dict):\n",
    "        self.repo_name = repo_dict['name']\n",
    "        self.repo_full_name = repo_dict['full_name']\n",
    "        owner = repo_dict['owner']\n",
    "        self.owner = owner['login']\n",
    "        self.count = 0\n",
    "    def __init__(self, owner, repo):\n",
    "        self.repo_name = repo\n",
    "        self.repo_full_name = owner+'/'+self.repo_name\n",
    "        self.owner = owner\n",
    "        self.count = 0\n",
    "    def add_one(self):\n",
    "        self.count += 1\n",
    "        \n",
    "    def key(self):\n",
    "        return self.repo_full_name\n",
    "\n",
    "\n",
    "q = Query()\n",
    "\n",
    "class DoSomething:\n",
    "    def doIt(self):\n",
    "\n",
    "        if 0 == 1:    \n",
    "            with open('./repo_classes.json', \"r\") as r:\n",
    "                array = json.load(r)\n",
    "        else:\n",
    "            array = {}\n",
    "            with open('./new_repo.log', 'r') as r:\n",
    "                for l in r.readlines():\n",
    "                    key = l[:-1] #Strip off carriage return\n",
    "                    s = key.split('/')\n",
    "                    array[key] = {'owner':s[0], 'repo_name':s[1], 'repo_full_name':key, 'count':0}\n",
    "        q.preload_alias_maps()\n",
    "        if exists('./hackers.json'):\n",
    "            with open('./hackers.json', 'r') as r:\n",
    "                q.hackers = json.load(r)\n",
    "        elif q.resolved_alias_map is not None and len(q.resolved_alias_map) > 0:\n",
    "            for alias in q.resolved_alias_map:\n",
    "                user_id = q.resolved_alias_map[alias]\n",
    "                if user_id not in q.hackers.keys():\n",
    "                    q.hackers[user_id] = []\n",
    "                q.hackers[user_id].append(alias) \n",
    "\n",
    "        for n in array.values():\n",
    "            owner = n['owner']\n",
    "            repo_name = n['repo_name']\n",
    "            repo = RepoName(owner, repo_name)\n",
    "            print('Processing', owner, repo_name)\n",
    "            repo_base_dir = './repos'\n",
    "            result_base_dir = './results'\n",
    "            repo_path = repo_base_dir+'/'+repo.key()\n",
    "            result_path = result_base_dir+'/'+repo.key()\n",
    "            json_stats_file_name = result_path+'/commit_stat_log.json'\n",
    "        #    stat_req_set = StatRequirementSet()\n",
    "            numstat_req_set = NumstatRequirementSet()\n",
    "            last_date = datingdays.fromisoformat('1972-12-26T03:23:01.123456-07:00')\n",
    "\n",
    "            if (os.path.isdir(repo_base_dir) == False):\n",
    "                print('######### Cannot find '+repo_base_dir+'  Creating it!')\n",
    "                os.makedirs(repo_base_dir)\n",
    "            if os.path.isdir(result_base_dir) == False:\n",
    "                print('Cannot find',result_base_dir,'Creating it!')\n",
    "                os.makedirs(result_base_dir)\n",
    "            if os.path.isdir(result_base_dir+'/'+owner) == False:\n",
    "                os.makedirs(result_base_dir+'/'+owner)\n",
    "            if os.path.isdir(result_base_dir+'/'+owner+'/'+repo_name) == False:\n",
    "                os.makedirs(result_base_dir+'/'+owner+'/'+repo_name)\n",
    "            if (os.path.isdir(repo_base_dir+\"/\"+owner) == False):\n",
    "                os.makedirs(repo_base_dir+\"/\"+owner)\n",
    "            url = 'https://github.com/'+owner+'/'+repo_name+'.git'\n",
    "            cache_date = None\n",
    "            if (os.path.isdir(repo_path) == False):\n",
    "                Repo.clone_from(url, repo_path)\n",
    "            else:\n",
    "                rp = Repo(repo_path)\n",
    "                remote = rp.remote()\n",
    "                remote.pull()\n",
    "                if exists(json_stats_file_name):\n",
    "                    try:\n",
    "                        cache_date = os.path.getmtime(json_stats_file_name)\n",
    "                        with open(json_stats_file_name) as j:\n",
    "                            numstat_req_set.resultArray = json.load(j)\n",
    "                        for item in numstat_req_set.resultArray:\n",
    "                            q.commit_cache_map[item['commit']] = item\n",
    "                    except Exception as e:\n",
    "                        cache_date = None\n",
    "                        print('Error encountered trying to parse', json_stats_file_name, e)\n",
    "\n",
    "            need_stats = True\n",
    "            rep = Git(repo_path)\n",
    "            if cache_date is not None:\n",
    "                system_tz = timezone(time.tzname[0])        \n",
    "                then = datingdays.now(system_tz)\n",
    "                file_date = datingdays.fromtimestamp(cache_date, tz=system_tz)\n",
    "\n",
    "                # Add call to rep.log('-1') to get the date from the latest change\n",
    "                #  If that date is less than the date on the cached stats file\n",
    "                #  then skip this one by loading the previous stats file.\n",
    "                info = rep.log('-1')\n",
    "                for n in info.splitlines():\n",
    "                    prefix = 'Date: '\n",
    "                    if n.startswith(prefix):\n",
    "                        new_date = n[len(prefix):].strip()\n",
    "                        dt = datingdays.strptime(new_date, '%a %b %d %H:%M:%S %Y %z')\n",
    "                        then = then - (then - dt)\n",
    "                        print(file_date.isoformat(), 'Last stats run')\n",
    "                        print(then.isoformat(), 'Last Git Modification')\n",
    "                        if then < file_date:\n",
    "                            need_stats = False\n",
    "\n",
    "                #print(info)\n",
    "                #Parse the line that starts with Date\n",
    "                #Date:   Mon May 16 19:14:08 2022 +0200\n",
    "\n",
    "            if need_stats:        \n",
    "                print('Generating Stats for '+repo_path)\n",
    "                stat = rep.log('--numstat')\n",
    "                numstat_req_set.processDocument(stat)\n",
    "\n",
    "            q.repos[repo.owner+'/'+repo.repo_name] = numstat_req_set.resultArray.copy()\n",
    "\n",
    "            if repo.owner not in q.json_repo_map.keys():\n",
    "                q.json_repo_map[repo.owner] = {}\n",
    "            q.json_repo_map[repo.owner][repo.repo_name] = q.repos[repo.key()]\n",
    "            with open(json_stats_file_name, 'w') as out:\n",
    "                out.write(json.dumps(numstat_req_set.resultArray, indent=2))\n",
    "            for rae in numstat_req_set.resultArray:\n",
    "                commit_id = rae['commit']\n",
    "                alias = rae['Author']\n",
    "                q.add_alias(alias, commit_id)\n",
    "                q.add_commit_id(commit_id, repo)\n",
    "\n",
    "        print('Done loading!')\n",
    "\n",
    "        q.resolve_aliases()\n",
    "\n",
    "        with open('./aliasMap.json', 'w') as out:\n",
    "            out.write(json.dumps(q.resolved_alias_map, indent=2))\n",
    "\n",
    "        with open('./new_repos.json', 'w') as out:\n",
    "            out.write(json.dumps(q.repos, indent=2))\n",
    "        with open('./hackers.json', 'w') as out:\n",
    "            out.write(json.dumps(q.hackers, indent=2))\n",
    "\n",
    "        for alias in q.aliases.keys():\n",
    "            v = q.aliases[alias]\n",
    "            print('Alias ', alias, ' has ', len(v), ' commits')\n",
    "\n",
    "        print('How many hackers?', len(q.hackers))    \n",
    "        repo_counter = {}\n",
    "        call_count = 0\n",
    "        if 1 == 0:\n",
    "            with open('./new_repo.log', 'w') as new_repo_log:\n",
    "                for hacker in q.hackers:\n",
    "                    done = False\n",
    "                    q.reset_last_date()\n",
    "                    last_count = -1\n",
    "                    while not done:\n",
    "                        body = q.load_hacker_url(hacker)\n",
    "                        call_count += 1\n",
    "                        if call_count % 25 == 0:\n",
    "                            print(call_count, 'rest API calls made')\n",
    "\n",
    "                        if (body == None):\n",
    "                            print('Unable to load JSON')\n",
    "                            done = True\n",
    "                        else:\n",
    "                            total_count = body['total_count']\n",
    "                            if (total_count == last_count):\n",
    "                                print('Identical result set found.  Moving on.', total_count, last_count)\n",
    "                                done = True\n",
    "                            else:\n",
    "                                print(total_count, 'remaining commits for user', hacker)\n",
    "                            last_count = total_count\n",
    "                            if total_count > 20000:\n",
    "                                print('Yikes!', total_count, ' seems like a few too many')\n",
    "                                done = True\n",
    "                            incomplete_results = body['incomplete_results']\n",
    "                #            print(total_count)\n",
    "                #            print(incomplete_results)\n",
    "                            array = body['items'];\n",
    "                            if (array == None or len(array) < 1):\n",
    "                                done = True\n",
    "                            else:\n",
    "                                for n in array:\n",
    "                                    repo = n['repository']\n",
    "                                    repo_full_name = repo['full_name']\n",
    "                                    counter = None\n",
    "                                    if repo_full_name not in repo_counter:\n",
    "                                        counter = RepoCounter(repo)\n",
    "                                        repo_counter[repo_full_name] = counter\n",
    "                                        print('New repo found!', repo_full_name)\n",
    "                                        new_repo_log.write(repo_full_name+'\\n')\n",
    "                                    else:\n",
    "                                        counter = repo_counter[repo_full_name]\n",
    "                                    counter.add_one()\n",
    "\n",
    "                                    commit = n['commit']\n",
    "                                    comAuth = commit['author']\n",
    "                                    q.set_last_date(comAuth['date'])\n",
    "                                if (total_count < 100 and incomplete_results == False):\n",
    "                                    done = True\n",
    "\n",
    "try:\n",
    "    DoSomething().doIt()\n",
    "except KeyboardInterrupt as ki:\n",
    "    print('Keyboard Interrupt!  Leaving...')\n",
    "except Exception as e:\n",
    "    print('Unexpected error encountered:', e)\n",
    "finally:\n",
    "    q.stop_monitor()\n",
    "\n",
    "try:\n",
    "    with open('./hackers.json', 'w') as out:\n",
    "        out.write(json.dumps(q.hackers, indent=2))\n",
    "except:\n",
    "    print('Unable to write out ./hackers.json')\n",
    "\n",
    "try:    \n",
    "    with open('./repo_classes.json', 'w') as out:\n",
    "        out.write(json.dumps(repo_counter,default=lambda o: o.__dict__, \n",
    "                sort_keys=True,indent=2))\n",
    "except:\n",
    "    print('Unable to write out ./repo_classes.json')\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87908377-011b-4832-80ec-172dd09194fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.stop_monitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b642d46-ecf8-468e-b4a0-a82c3521d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as datingdays\n",
    "fmt = '%Y-%m-%dT%H:%M:%S.%f%z'\n",
    "t = '2020-01-28T15:47:53.000+01:00'\n",
    "rslt = datingdays.strptime(t, fmt)\n",
    "print(rslt)\n",
    "print(rslt.strftime(fmt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d4809-4dd5-40c5-b85a-67b31a391e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from pytz import timezone\n",
    "d = dt.fromisoformat('2022-04-11T19:14:33.000+02:00')\n",
    "\n",
    "#az = timezone('US/Arizona')\n",
    "#d2 = az.localize(d, is_dst=False)\n",
    "#d2              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ba6e9-d798-4d66-85e8-8d1cd189da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "# Given timestamp in string\n",
    "time_str = '24/7/2021 11:13:08.230010'\n",
    "date_format_str = '%d/%m/%Y %H:%M:%S.%f'\n",
    "# create datetime object from timestamp string\n",
    "given_time = datetime.strptime(time_str, date_format_str)\n",
    "print('Given Time: ', given_time)\n",
    "n = 2\n",
    "# Subtract 2 hours from datetime object\n",
    "final_time = given_time - timedelta(hours=n)\n",
    "print('Final Time (2 hours ahead of given time ): ', final_time)\n",
    "# Convert datetime object to string in specific format \n",
    "final_time_str = final_time.strftime('%d/%m/%Y %H:%M:%S.%f')\n",
    "print('Final Time as string object: ', final_time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d2a1dc-6ebf-40fa-8506-e26bf360fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.github.com/search/commit/fb5f372203f70cc7580f8e9806c00405524649d7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bdd465-317d-46c2-8aa4-a62cfc94d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print('Getting started')\n",
    "rev = {}\n",
    "with open('./aliasMap.json', \"r\") as r:\n",
    "    body = json.load(r)\n",
    "    for k in body.keys():\n",
    "        v = body[k]\n",
    "        if v not in rev.keys():\n",
    "            rev[v] = []\n",
    "        rev[v].append(k)\n",
    "with open('./idToAliasMap.json', 'w') as w:\n",
    "    w.write(json.dumps(rev, indent=2))    \n",
    "print('Done!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e76493-e5b4-45db-bda8-5f2a18bdac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./hackers.json', 'w') as out:\n",
    "    out.write(json.dumps(q.hackers, indent=2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26397a84-4ada-42a0-a11c-ee8855a6558e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
