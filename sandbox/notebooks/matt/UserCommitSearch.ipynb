{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "477d1bc5-5366-4ae3-afa7-84c3e75142cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def introspect(obj):\n",
    "  for func in [type, id, dir, vars, callable]:\n",
    "        print(\"%s(%s):\\t\\t%s\" % (func.__name__, introspect.__code__.co_varnames[0], func(obj)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3518a0af-e9c9-4b35-ae8d-a9024806e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, enum;\n",
    "from abc import ABC, abstractmethod\n",
    "import sys\n",
    "import traceback, inspect, json\n",
    "\n",
    "        \n",
    "class File:\n",
    "    dir = None\n",
    "    fileName = None\n",
    "    fullyQualified = None\n",
    "    def __init__(self, dir, fileName):\n",
    "        self.dir = dir\n",
    "        self.fileName = fileName\n",
    "        self.fullyQualified = dir + '/' + fileName;\n",
    "        \n",
    "def addFiles(fileList, directory):\n",
    "   for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            fileList.append(File(root, file))\n",
    "        for subdir in dirs:\n",
    "            addFiles(fileList, subdir);\n",
    "            \n",
    "    \n",
    "class Result(enum.Enum):\n",
    "    failedMatch = 0           #didn't match - reset to zero\n",
    "    matchedProgress = 1       #all requirements met - move on to the next requirement \n",
    "    oneOfManyMatches = 2      #Data gathered - keep on feeding me more lines\n",
    "    endOfSet = 3              #contiguous set has ended - re-analyze this line\n",
    "    gameSetMatch = 4          #Found end of data set - go spit out results\n",
    "    lookForExtraComment = 5\n",
    "\"\"\"\n",
    "    define an array of matching patterns\n",
    "    Params:\n",
    "    1 - Index to expect parameter 2\n",
    "    2 - Space delimited match string\n",
    "    3 - Data array index to capture\n",
    " - Populated value - starts as None (null)\n",
    "\"\"\"\n",
    "class Requirement(ABC):\n",
    "    @abstractmethod\n",
    "    def testline(self, line):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def reset(self):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def addResults(self, dictionary):\n",
    "        pass\n",
    "\n",
    "class EndOfNumStat(Requirement):\n",
    "    def testline(self, line):\n",
    "        return Result.gameSetMatch\n",
    "    def reset(self):\n",
    "        pass\n",
    "    def addResults(self, dictionary):\n",
    "        pass\n",
    "    \n",
    "class Splicer(Requirement):\n",
    "    def __init__(self, matchIdx, matchValue, captureIndex, foundValue):\n",
    "        self.matchIdx = matchIdx\n",
    "        self.matchValue = matchValue\n",
    "        self.captureIndex = captureIndex\n",
    "        self.foundValue = foundValue\n",
    "    def addResults(self, dictionary):\n",
    "        dictionary[self.matchValue] = self.foundValue;\n",
    "    @abstractmethod\n",
    "    def getSpliceChar(self):\n",
    "        pass\n",
    "    def testline(self, line):\n",
    "        sp = line.split(self.getSpliceChar())\n",
    "        if (sp is not None and \n",
    "            len(sp) > self.matchIdx and \n",
    "            len(sp) > self.captureIndex and \n",
    "            self.matchValue == sp[self.matchIdx]):\n",
    "            self.foundValue = sp[self.captureIndex].strip()\n",
    "            return Result.matchedProgress\n",
    "        return Result.failedMatch\n",
    "    def reset(self):\n",
    "        self.foundValue = None\n",
    "        \n",
    "class SpaceSplicer(Splicer):\n",
    "    def getSpliceChar(self):\n",
    "        return ' '\n",
    "\n",
    "class ColonSplicer(Splicer): #Ouch?\n",
    "    def getSpliceChar(self):\n",
    "        return ':'\n",
    "    def testline(self, line):\n",
    "        retVal = super().testline(line)\n",
    "        if (retVal == Result.matchedProgress):\n",
    "            if (self.matchValue == 'Date'):\n",
    "                i = line.index('Date:')\n",
    "                self.foundValue = line[i+5::]\n",
    "                self.foundValue = line.strip()\n",
    "        return retVal\n",
    "    \n",
    "class Blank(Requirement):\n",
    "    def reset(self):\n",
    "        return;\n",
    "    def addResults(self, dictionary):\n",
    "        return;\n",
    "    def testline(self, line):\n",
    "        if (line is None):\n",
    "            print('Not sure what to: do with None-zies')\n",
    "        elif (len(line.strip()) == 0):\n",
    "            #blank line!\n",
    "            return Result.matchedProgress\n",
    "        return Result.failedMatch\n",
    "class Comment(Requirement):\n",
    "    def reset(self):\n",
    "        self.comment = None;\n",
    "    def addResults(self, dictionary):\n",
    "        return;\n",
    "    def testline(self, line):\n",
    "        self.comment = line.strip()\n",
    "        return Result.matchedProgress\n",
    "    \n",
    "class FileInfo:\n",
    "    def __init__(self, extension):\n",
    "        self.extension = extension\n",
    "        self.textLineCount = 0;\n",
    "        self.binByteCount= 0;\n",
    "        self.isBinary = False\n",
    "        self.inserts = 0\n",
    "        self.deletes = 0\n",
    "        self.occurrences = 0\n",
    "def removeEmptyStrings(array):\n",
    "    retVal = []\n",
    "    for k in array:\n",
    "        if (len(k) > 0):\n",
    "            retVal.append(k)\n",
    "    return retVal\n",
    "def addIntValue(dictionary, key, intval):\n",
    "    curVal = dictionary.get(key)\n",
    "    if (curVal is None):\n",
    "        curVal = 0\n",
    "    dictionary[key] = curVal + intval;\n",
    "class FileCommit(Requirement):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.extensionDic = {}\n",
    "        self.foundOneOrMoreLines = False\n",
    "    def addResults(self, dictionary):\n",
    "        fileTypes = dictionary.get('fileTypes')\n",
    "        if (fileTypes is None):\n",
    "            fileTypes = {}\n",
    "            dictionary['fileTypes'] = fileTypes;\n",
    "        for key in self.extensionDic:\n",
    "            fi = self.extensionDic.get(key)\n",
    "            sumDic = fileTypes.get(fi.extension)\n",
    "            if (sumDic is None):\n",
    "                sumDic = {}\n",
    "                fileTypes[fi.extension] = sumDic\n",
    "            addIntValue(sumDic, 'textLineCount', fi.textLineCount)\n",
    "            addIntValue(sumDic, 'binByteCount', fi.binByteCount)\n",
    "            addIntValue(sumDic, 'inserts', fi.inserts)\n",
    "            addIntValue(sumDic, 'deletes', fi.deletes)\n",
    "            addIntValue(sumDic, 'occurrences', fi.occurrences)\n",
    "            \n",
    "    def getExt(self, ext):\n",
    "        fi = self.extensionDic.get(ext)\n",
    "        if (fi is None):\n",
    "            fi = FileInfo(ext)\n",
    "            self.extensionDic[ext] = fi\n",
    "        return fi\n",
    "    @abstractmethod\n",
    "    def split(self, line):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def processStatistics(self, line, file_info, extension):\n",
    "        pass\n",
    "    \n",
    "        \n",
    "    def testline(self, line):\n",
    "#        print('Testing for commit line: \"'+line+'\"')\n",
    "        fileNamePortion, statsPortion = self.split(line)\n",
    "        validData = False;\n",
    "        if (fileNamePortion is not None and statsPortion is not None):\n",
    "            fileNameArray = fileNamePortion.split('/');\n",
    "            fileName = fileNameArray[len(fileNameArray)-1];\n",
    "#            print('Filename spliced into:'+fileName)\n",
    "            dotSplit = fileName.split('.')\n",
    "            ext = 'noexttext'\n",
    "            if (fileName.startswith('.') == False and len(dotSplit) > 1):\n",
    "                ext = dotSplit[len(dotSplit)-1].strip() #last element (e.g. '.txt')\n",
    "                ext = removeEmptyStrings(ext.split('}'))[0]\n",
    "            fi = self.getExt(ext)\n",
    "            fi.occurrences += 1\n",
    "            validData = self.processStatistics(statsPortion, fi, ext)\n",
    "\n",
    "        returnVal = Result.endOfSet\n",
    "        if (validData == True):\n",
    "            self.foundOneOrMoreLines = True\n",
    "#            print('Returning '+str(Result.oneOfManyMatches))\n",
    "            returnVal = Result.oneOfManyMatches\n",
    "        elif (self.foundOneOrMoreLines == False):\n",
    "            returnVal = Result.lookForExtraComment\n",
    "                \n",
    "        return returnVal\n",
    "    \n",
    "class StatFileCommit(FileCommit):\n",
    "    def split(self, line):\n",
    "        sp = line.split('|')\n",
    "        if (len(sp) < 2):\n",
    "            return None, None\n",
    "        return sp[0], sp[1]\n",
    "\n",
    "    def processStatistics(self, line, fi, ext):\n",
    "        validData = False;\n",
    "        size = removeEmptyStrings(line.split(' '))        \n",
    "#            print('Size element array is:'+str(size))\n",
    "        if (size[0].startswith('Bin')): #binary file - handle separately\n",
    "            if (ext == 'noexttext'):\n",
    "                fi.occurrences -= 1\n",
    "                ext = 'noextbin'\n",
    "                fi = self.getExt(ext)\n",
    "                fi.occurrences += 1\n",
    "            if (len(size) > 1):\n",
    "                sizeBefore = int(size[1]) if size[1].isnumeric() else -1\n",
    "                sizeAfter = int(size[3]) if size[3].isnumeric() else -1\n",
    "                if (sizeBefore >= 0 and sizeAfter >= 0):\n",
    "                    validData = True\n",
    "                    fi.isBinary = True\n",
    "                    fi.binByteCount += (sizeAfter - sizeBefore)\n",
    "            else:\n",
    "                validData = True\n",
    "                fi.isBinary = True\n",
    "        elif (size[0].isnumeric and len(size[0]) > 0):\n",
    "            fi.isBinary = False\n",
    "            try:\n",
    "                lc = int(size[0])\n",
    "                fi.textLineCount += lc\n",
    "                plusCount = 0\n",
    "                minusCount = 0\n",
    "                if (lc < 1 and len(size) < 2):\n",
    "                    #all done here\n",
    "                    validData = True\n",
    "                else:\n",
    "                    plus = size[1].split('+')\n",
    "                    for p in plus:\n",
    "                        if (len(p) == 0):\n",
    "                            plusCount += 1\n",
    "                        else:\n",
    "                            mi = len(p.split('-')) - 1\n",
    "                            minusCount += mi\n",
    "                        if (plusCount > 0 or minusCount > 0):\n",
    "                            validData = True\n",
    "                            fi.inserts = int(fi.textLineCount * ((plusCount * 1.0) / (plusCount + minusCount)))\n",
    "                            fi.deletes = fi.textLineCount - fi.inserts\n",
    "                        else:\n",
    "                            print('No bueno!')\n",
    "            except:\n",
    "                print('Exception encountered parsing:', size[0])\n",
    "        return validData\n",
    "                        \n",
    "class NumStatFileCommit(FileCommit):\n",
    "    def split(self, line):\n",
    "        try:\n",
    "            chunks = line.split('\\t')\n",
    "            file_name_portion = chunks[2]\n",
    "            stats_portion = chunks[0]+' '+chunks[1]\n",
    "            if (chunks[0].isnumeric() or chunks[0] == '-') and (chunks[1].isnumeric() or chunks[0] == '-'):\n",
    "                return file_name_portion, stats_portion\n",
    "        except:\n",
    "            pass\n",
    "        return None, None\n",
    "    def processStatistics(self, line, fi, ext):\n",
    "        validData = False\n",
    "        try:\n",
    "            sa = line.split(' ')\n",
    "            if len(sa) == 2:\n",
    "                if sa[0] == '-':\n",
    "                    #binary file\n",
    "                    fi.isBinary = True\n",
    "                    validData = True\n",
    "                elif sa[0].isnumeric() and sa[1].isnumeric:\n",
    "                    fi.isBinary = False\n",
    "                    fi.inserts += int(sa[0])\n",
    "                    fi.deletes += int(sa[1])\n",
    "                    validData = True\n",
    "        except:\n",
    "            print('NumStatFileCommit Error parsing:',line)\n",
    "        return validData\n",
    "        \n",
    "class Summary(Requirement):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.junk = ''\n",
    "        self.totals = {}\n",
    "    def testline(self, line):\n",
    "        #print('Testing for Summary line ('+str(line)+')')\n",
    "        sp = line.split(',')\n",
    "        for elem in sp:\n",
    "            spaceDelim = removeEmptyStrings(elem.split(' '))\n",
    "            if (len(spaceDelim) > 1):\n",
    "                self.totals[spaceDelim[1]] = spaceDelim[0]\n",
    "            else:\n",
    "                print('ERROR - Summary line should have comma-separated change and insertion totals:'+line)\n",
    "        return Result.gameSetMatch\n",
    "    def addResults(self, dictionary):\n",
    "        dictionary.update(self.totals)\n",
    "\n",
    "class RequirementSet:\n",
    "    def processDocument(self, multiLineString):\n",
    "        for line in multiLineString.splitlines():\n",
    "            self.testline(line)\n",
    "\n",
    "    def getReqArray(self):\n",
    "        return self.reqArray;\n",
    "    @abstractmethod\n",
    "    def setup_requirements(self):\n",
    "        pass\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reqArray = []\n",
    "        self.setup_requirements()\n",
    "        self.reqIndex = 0\n",
    "        self.dataMatchesFound = 0\n",
    "        self.indexErrorDic = {}\n",
    "        self.resultArray = []\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.reqIndex = 0;\n",
    "        self.dataMatchesFound = 0;\n",
    "        self.resultDictionary = {}\n",
    "        for req in self.getReqArray():\n",
    "            req.reset();\n",
    "    def processResult(self, line, rslt):\n",
    "#        if (rslt != Result.failedMatch):\n",
    "#            print('Processing['+str(self.reqIndex)+']: '+str(rslt));\n",
    "        if (rslt == Result.failedMatch):\n",
    "            self.reset();\n",
    "            self.reqIndex = 0;\n",
    "        elif (rslt == Result.matchedProgress):\n",
    "            self.reqIndex += 1\n",
    "            if (self.reqIndex >= len(self.reqArray)):\n",
    "                print('ERROR - Last element of RequirementSet cannot return Result.matchedProgress')\n",
    "                self.reset()\n",
    "                self.reqIndex = 0\n",
    "        elif (rslt == Result.oneOfManyMatches):\n",
    "            #Just keep reading until done\n",
    "            self.dataMatchesFound += 1\n",
    "#            print('Just one of many matches ('+str(self.dataMatchesFound)+' total)')\n",
    "        elif (rslt == Result.endOfSet):\n",
    "            self.reqIndex += 1\n",
    "            self.testline(line)\n",
    "        elif (rslt == Result.gameSetMatch):\n",
    "#            print('Game set match!')\n",
    "            for req in self.reqArray:\n",
    "                req.addResults(self.resultDictionary)\n",
    "            self.resultArray.append(self.resultDictionary.copy())\n",
    "            self.reset()\n",
    "        elif (rslt == Result.lookForExtraComment):\n",
    "            self.reqIndex = 4 #Go back to the stage that\n",
    "            self.testline(line)\n",
    "        else:\n",
    "            self.reqIndex = 0\n",
    "            cnt = self.indexErrorDic.get(self.reqIndex)\n",
    "            if (cnt is None):\n",
    "                cnt = 0;\n",
    "                print('ERROR - Unknown result type from requirement index: '+str(self.reqIndex))\n",
    "            cnt += 1;\n",
    "            self.indexErrorDic[self.reqIndex] = cnt;\n",
    "\n",
    "    def testline(self, line):\n",
    "        if (self.reqIndex >= len(self.reqArray)):\n",
    "            print('ERROR - RequirementIndex out of range!')\n",
    "            self.reset();\n",
    "            self.reqIndex = 0;\n",
    "            sys.exit()\n",
    "        else:\n",
    "            self.processResult(line, self.reqArray[self.reqIndex].testline(line))\n",
    "            \n",
    "\n",
    "        \n",
    "                        \n",
    "class StatRequirementSet(RequirementSet):\n",
    "    def setup_requirements(self):\n",
    "        reqArray = super().getReqArray()\n",
    "        reqArray.append( SpaceSplicer(0, 'commit', 1, None) )\n",
    "        reqArray.append( ColonSplicer(0, 'Author', 1, None) )\n",
    "        reqArray.append( ColonSplicer(0, 'Date', 1, None) )\n",
    "        reqArray.append( Blank() )\n",
    "        reqArray.append( Comment() )\n",
    "        reqArray.append( Blank() )\n",
    "        reqArray.append( StatFileCommit() )\n",
    "        reqArray.append( Summary() )\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "class NumstatRequirementSet(RequirementSet):        \n",
    "    def setup_requirements(self):\n",
    "        reqArray = super().getReqArray()\n",
    "        reqArray.append( SpaceSplicer(0, 'commit', 1, None) )\n",
    "        reqArray.append( ColonSplicer(0, 'Author', 1, None) )\n",
    "        reqArray.append( ColonSplicer(0, 'Date', 1, None) )\n",
    "        reqArray.append( Blank() )\n",
    "        reqArray.append( Comment() )\n",
    "        reqArray.append( Blank() )\n",
    "        reqArray.append( NumStatFileCommit() )\n",
    "        reqArray.append( EndOfNumStat() )\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfed32ff-d098-4bd8-afbf-54dcb42226db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing adbenitez mailman\n",
      "Generating Stats for ./repos/adbenitez/mailman\n",
      "Processing akintu akintu\n",
      "Generating Stats for ./repos/akintu/akintu\n",
      "Processing bbci wyrm\n",
      "Generating Stats for ./repos/bbci/wyrm\n",
      "Processing berinhard pyp5js\n",
      "Generating Stats for ./repos/berinhard/pyp5js\n",
      "Processing bhrutledge jahhills.com\n",
      "Generating Stats for ./repos/bhrutledge/jahhills.com\n",
      "Processing Biohazard1976 pi\n",
      "Generating Stats for ./repos/Biohazard1976/pi\n",
      "Processing Biohazard1976 pip\n",
      "Generating Stats for ./repos/Biohazard1976/pip\n",
      "Processing bskinn cpython-release-feed\n",
      "Generating Stats for ./repos/bskinn/cpython-release-feed\n",
      "Processing bskinn flake8-bot\n",
      "Generating Stats for ./repos/bskinn/flake8-bot\n",
      "Processing ClearcodeHQ pytest-postgresql\n",
      "Generating Stats for ./repos/ClearcodeHQ/pytest-postgresql\n",
      "Processing controversial luk.ke\n",
      "Generating Stats for ./repos/controversial/luk.ke\n",
      "Processing Convex-Dev convex\n",
      "Generating Stats for ./repos/Convex-Dev/convex\n",
      "Processing datacraft-dsc starfish-py\n",
      "Generating Stats for ./repos/datacraft-dsc/starfish-py\n",
      "Processing DataDog integrations-core\n",
      "Generating Stats for ./repos/DataDog/integrations-core\n",
      "Processing datalatte-ai Datalatte-marketplace\n",
      "Generating Stats for ./repos/datalatte-ai/Datalatte-marketplace\n",
      "Processing deltaDAO market-foreverontheblockchain\n",
      "Generating Stats for ./repos/deltaDAO/market-foreverontheblockchain\n",
      "Processing deltaDAO mvg-portal\n",
      "Generating Stats for ./repos/deltaDAO/mvg-portal\n",
      "Processing deltaDAO portal-euprogigant\n",
      "Generating Stats for ./repos/deltaDAO/portal-euprogigant\n",
      "Processing deltaDAO portal-safeFBDC\n",
      "Generating Stats for ./repos/deltaDAO/portal-safeFBDC\n",
      "Processing deltaDAO portal-udl\n",
      "Generating Stats for ./repos/deltaDAO/portal-udl\n",
      "Processing DiddiLeija diddiparser2\n",
      "Generating Stats for ./repos/DiddiLeija/diddiparser2\n",
      "Processing DiddiLeija text_formatter\n",
      "Generating Stats for ./repos/DiddiLeija/text_formatter\n",
      "Processing drf-forms drf-schema-adapter\n",
      "Generating Stats for ./repos/drf-forms/drf-schema-adapter\n",
      "Processing evemorgen SMaDA-AGH\n",
      "Generating Stats for ./repos/evemorgen/SMaDA-AGH\n",
      "Processing flathub com.valvesoftware.Steam\n",
      "Generating Stats for ./repos/flathub/com.valvesoftware.Steam\n",
      "Processing floss50 keeper-experimental\n",
      "Generating Stats for ./repos/floss50/keeper-experimental\n",
      "Processing floss50 ocean-explorer\n",
      "Generating Stats for ./repos/floss50/ocean-explorer\n",
      "Processing FMenhorn BGCEGit\n",
      "Generating Stats for ./repos/FMenhorn/BGCEGit\n",
      "Processing fnreality asmgraph\n",
      "Generating Stats for ./repos/fnreality/asmgraph\n",
      "Processing gevent gevent\n",
      "Generating Stats for ./repos/gevent/gevent\n",
      "Processing gitlabhq terraform-provider-gitlab\n",
      "Generating Stats for ./repos/gitlabhq/terraform-provider-gitlab\n",
      "Processing golang pkgsite\n",
      "Generating Stats for ./repos/golang/pkgsite\n",
      "Processing graphite-project graphite-web\n",
      "Generating Stats for ./repos/graphite-project/graphite-web\n",
      "Processing gustavklopp mailman\n",
      "Generating Stats for ./repos/gustavklopp/mailman\n",
      "Processing Harsh-Avinash court-hero-ocean-api\n",
      "Generating Stats for ./repos/Harsh-Avinash/court-hero-ocean-api\n",
      "Processing jamiehewitt15 cryptophotos\n",
      "Generating Stats for ./repos/jamiehewitt15/cryptophotos\n",
      "Processing jw stilus\n",
      "Generating Stats for ./repos/jw/stilus\n",
      "Processing kiwitcms Kiwi\n",
      "Generating Stats for ./repos/kiwitcms/Kiwi\n",
      "Processing malikoth dotfiles\n",
      "Generating Stats for ./repos/malikoth/dotfiles\n",
      "Processing Mattlk13 theupdateframework\n",
      "Generating Stats for ./repos/Mattlk13/theupdateframework\n",
      "Processing mayeut manylinux-timeline\n",
      "Generating Stats for ./repos/mayeut/manylinux-timeline\n",
      "Processing mblayman conductor\n",
      "Generating Stats for ./repos/mblayman/conductor\n",
      "Processing mblayman homeschool\n",
      "Generating Stats for ./repos/mblayman/homeschool\n",
      "Processing mblayman mattlayman.com\n",
      "Generating Stats for ./repos/mblayman/mattlayman.com\n",
      "Processing mozilla glam\n",
      "Generating Stats for ./repos/mozilla/glam\n",
      "Processing mozilla zamboni\n",
      "Generating Stats for ./repos/mozilla/zamboni\n",
      "Processing nanonyme simplecpreprocessor\n",
      "Generating Stats for ./repos/nanonyme/simplecpreprocessor\n",
      "Processing nevermined-io contracts\n",
      "Generating Stats for ./repos/nevermined-io/contracts\n",
      "Processing ninox-iot tuf\n",
      "Generating Stats for ./repos/ninox-iot/tuf\n",
      "Processing oceanprotocol aquarius\n",
      "Generating Stats for ./repos/oceanprotocol/aquarius\n",
      "Processing oceanprotocol-archive brizo\n",
      "Generating Stats for ./repos/oceanprotocol-archive/brizo\n",
      "Processing oceanprotocol barge\n",
      "Generating Stats for ./repos/oceanprotocol/barge\n",
      "Processing oceanprotocol contracts\n",
      "Generating Stats for ./repos/oceanprotocol/contracts\n",
      "Processing oceanprotocol docs\n",
      "Generating Stats for ./repos/oceanprotocol/docs\n",
      "Processing oceanprotocol market\n",
      "Generating Stats for ./repos/oceanprotocol/market\n",
      "Processing oceanprotocol ocean.js\n",
      "Generating Stats for ./repos/oceanprotocol/ocean.js\n",
      "Processing oceanprotocol ocean.py\n",
      "Generating Stats for ./repos/oceanprotocol/ocean.py\n",
      "Processing oceanprotocol RBAC-Server\n",
      "Generating Stats for ./repos/oceanprotocol/RBAC-Server\n",
      "Processing openstack swift\n",
      "Generating Stats for ./repos/openstack/swift\n",
      "Processing opscientia commons\n",
      "Generating Stats for ./repos/opscientia/commons\n",
      "Processing optimamodel optima\n",
      "Generating Stats for ./repos/optimamodel/optima\n",
      "Processing pdoc3 pdoc\n",
      "Generating Stats for ./repos/pdoc3/pdoc\n",
      "Processing powens padraig.io\n",
      "Generating Stats for ./repos/powens/padraig.io\n",
      "Processing pulp pulp\n",
      "Generating Stats for ./repos/pulp/pulp\n",
      "Processing pulp pulpcore-plugin\n",
      "Generating Stats for ./repos/pulp/pulpcore-plugin\n",
      "Processing PyO3 maturin\n",
      "Generating Stats for ./repos/PyO3/maturin\n",
      "Processing pypa manylinux\n",
      "Generating Stats for ./repos/pypa/manylinux\n",
      "Processing pypa packaging.python.org\n",
      "Generating Stats for ./repos/pypa/packaging.python.org\n",
      "Processing pypa pip\n",
      "Generating Stats for ./repos/pypa/pip\n",
      "Processing pypa warehouse\n",
      "Generating Stats for ./repos/pypa/warehouse\n",
      "Processing python-greenlet greenlet\n",
      "Generating Stats for ./repos/python-greenlet/greenlet\n",
      "Processing quicklers pypa1\n",
      "Generating Stats for ./repos/quicklers/pypa1\n",
      "Processing read-what-you-need rn-client\n",
      "Generating Stats for ./repos/read-what-you-need/rn-client\n",
      "Processing Reptiliano35 pip\n",
      "Generating Stats for ./repos/Reptiliano35/pip\n",
      "Processing robert-codecov ccpip\n",
      "Generating Stats for ./repos/robert-codecov/ccpip\n",
      "Processing rohankumardubey gevent\n",
      "Generating Stats for ./repos/rohankumardubey/gevent\n",
      "Processing roperi myband\n",
      "Generating Stats for ./repos/roperi/myband\n",
      "Processing rwdavi Tower-Defense-Game\n",
      "Generating Stats for ./repos/rwdavi/Tower-Defense-Game\n",
      "Processing sacdallago bio_embeddings\n",
      "Generating Stats for ./repos/sacdallago/bio_embeddings\n",
      "Processing sailfishos-mirror pip\n",
      "Generating Stats for ./repos/sailfishos-mirror/pip\n",
      "Processing sapphire1896 xcrun-WindowServer\n",
      "Generating Stats for ./repos/sapphire1896/xcrun-WindowServer\n",
      "Processing sayanarijit .files\n",
      "Generating Stats for ./repos/sayanarijit/.files\n",
      "Processing sayanarijit xplr\n",
      "Generating Stats for ./repos/sayanarijit/xplr\n",
      "Processing ScottAndrews1873 python-pip\n",
      "Generating Stats for ./repos/ScottAndrews1873/python-pip\n",
      "Processing SFDO-Tooling MetaDeploy\n",
      "Generating Stats for ./repos/SFDO-Tooling/MetaDeploy\n",
      "Processing SFDO-Tooling Metecho\n",
      "Generating Stats for ./repos/SFDO-Tooling/Metecho\n",
      "Processing stloma dotfiles\n",
      "Generating Stats for ./repos/stloma/dotfiles\n",
      "Processing terminal-labs rambo\n",
      "Generating Stats for ./repos/terminal-labs/rambo\n",
      "Processing terminusdb terminusdb-client-python\n",
      "Generating Stats for ./repos/terminusdb/terminusdb-client-python\n",
      "Processing terror solutions\n",
      "Generating Stats for ./repos/terror/solutions\n",
      "Processing theupdateframework python-tuf\n",
      "Generating Stats for ./repos/theupdateframework/python-tuf\n",
      "Processing tokenspice tokenspice\n",
      "Generating Stats for ./repos/tokenspice/tokenspice\n",
      "Processing turicas brasil.io\n",
      "Generating Stats for ./repos/turicas/brasil.io\n",
      "Processing tusharsadhwani blog\n",
      "Generating Stats for ./repos/tusharsadhwani/blog\n",
      "Processing venthur wyrm\n",
      "Generating Stats for ./repos/venthur/wyrm\n",
      "Processing vint21h django-opensearch\n",
      "Generating Stats for ./repos/vint21h/django-opensearch\n",
      "Processing vint21h django-xicon\n",
      "Generating Stats for ./repos/vint21h/django-xicon\n",
      "Processing wayveai freedesktop-sdk\n",
      "Generating Stats for ./repos/wayveai/freedesktop-sdk\n",
      "Processing wimglenn advent-of-code-wim\n",
      "Generating Stats for ./repos/wimglenn/advent-of-code-wim\n",
      "Processing wtolson gnsq\n",
      "Generating Stats for ./repos/wtolson/gnsq\n",
      "Processing ymyzk mypy-playground\n",
      "Generating Stats for ./repos/ymyzk/mypy-playground\n",
      "Processing ymyzk portfolio\n",
      "Generating Stats for ./repos/ymyzk/portfolio\n",
      "Done loading!\n",
      "Resolving [Mark Sapiro <mark@msapiro.net>] using commit ID: dfa72b74beb2e65649b551acd0603227de41acdd\n",
      "Creating new hacker object for msapiro [Mark Sapiro <mark@msapiro.net>]\n",
      "Resolving [Дилян Палаузов <git-dpa@aegee.org>] using commit ID: 3c0cbb5e8fb2d1130613a265841bda62182dc4fb\n",
      "Creating new hacker object for dilyanpalauzov [Дилян Палаузов <git-dpa@aegee.org>]\n",
      "Resolving [Дилян Палаузов <dilyan.palauzov@aegee.org>] using commit ID: ce7ac6724842874128b4bb674cf4849ba4d398ba\n",
      "Adding alias [Дилян Палаузов <dilyan.palauzov@aegee.org>] for user msapiro for a total of  2\n",
      "Resolving [Abhilash Raj <raj.abhilash1@gmail.com>] using commit ID: dde77a09cc7a4f45ec03818e7e34962a4b35ff77\n",
      "Creating new hacker object for maxking [Abhilash Raj <raj.abhilash1@gmail.com>]\n",
      "Resolving [Abhilash Raj <maxking@asynchronous.in>] using commit ID: 5c287c488fd1550a4f06339ed88d7cf17bc6c4fb\n",
      "Adding alias [Abhilash Raj <maxking@asynchronous.in>] for user maxking for a total of  2\n",
      "Resolving [dpa-weblate@aegee.org <dpa-weblate@aegee.org>] using commit ID: c2855b3b9ba85ea7c54c8335bf533a1193af75cd\n",
      "Creating new hacker object for weblate [dpa-weblate@aegee.org <dpa-weblate@aegee.org>]\n",
      "Resolving [s3lph <account-gitlab-ideynizv@kernelpanic.lol>] using commit ID: 04dba01a34f89a340d4e6966f32b3adddd30ea55\n",
      "Unable to find author node within JSON formatted result set\n",
      "Resolving [Weblate <hosted@weblate.org>] using commit ID: e6f9bb304cc3ff69edc2c13698a9c2053dfc02bb\n",
      "Adding alias [Weblate <hosted@weblate.org>] for user weblate for a total of  2\n",
      "Resolving [Jiří Morariu <jirkamorariu@gmail.com>] using commit ID: bd22cb2eaa991b971d9728bc0e9c7374266fb0ef\n",
      "Creating new hacker object for JirkaMorariu [Jiří Morariu <jirkamorariu@gmail.com>]\n",
      "Resolving [iiron <iiro.nummela@nkl.fi>] using commit ID: f0987d7a60afce5262f1c0ce7ad237c69768637d\n",
      "Creating new hacker object for iiron [iiron <iiro.nummela@nkl.fi>]\n",
      "Resolving [atagar <atagar1@gmail.com>] using commit ID: 29d2c21f5c5ca76430ff4a3aa1c4fa8c4837fe8a\n",
      "Creating new hacker object for atagar [atagar <atagar1@gmail.com>]\n",
      "Resolving [Pavel Valach <valach.pavel@gmail.com>] using commit ID: a74f84ab877cf6deb5cc231a6bf0b5b762dcb2d7\n",
      "Creating new hacker object for PaulosV [Pavel Valach <valach.pavel@gmail.com>]\n",
      "Resolving [Luiz Angelo Daros de Luca <luizluca@gmail.com>] using commit ID: 019433b8d657eb2ceb66f1b972cf2dcfc5143037\n",
      "Creating new hacker object for luizluca [Luiz Angelo Daros de Luca <luizluca@gmail.com>]\n",
      "Resolving [Kunal Mehta <legoktm@debian.org>] using commit ID: 9fd26a73d8051335a81408704745ec7b4408ac24\n",
      "Creating new hacker object for legoktm [Kunal Mehta <legoktm@debian.org>]\n",
      "Resolving [legoktm <legoktm@debian.org>] using commit ID: ee8dfef5ba1c36f8f1b17dfb7aa271d7b4538bf2\n",
      "Adding alias [legoktm <legoktm@debian.org>] for user legoktm for a total of  2\n",
      "Resolving [TommyLike Hu <tommylikehu@gmail.com>] using commit ID: 59049e41beebebf857f05c5b986a066904a79afe\n",
      "Creating new hacker object for TommyLike [TommyLike Hu <tommylikehu@gmail.com>]\n",
      "Resolving [Ngalim Siregar <ngalim.siregar@gmail.com>] using commit ID: f08f4cd8e8d0e137ee95c3d9bb4f60864278e679\n",
      "Creating new hacker object for nsiregar [Ngalim Siregar <ngalim.siregar@gmail.com>]\n",
      "Resolving [Aditya Komaravolu <komaravoluaditya@gmail.com>] using commit ID: c42fec13b3e0dfda0cc62e2317d31555dcf50ca9\n",
      "Creating new hacker object for Aditya-Komaravolu [Aditya Komaravolu <komaravoluaditya@gmail.com>]\n",
      "Resolving [Konstantinos Sitistas <kon.sitistas@gmail.com>] using commit ID: 0fac4376810e5dd023f92ac1f1d234d2347eb475\n",
      "Creating new hacker object for sitistas [Konstantinos Sitistas <kon.sitistas@gmail.com>]\n",
      "Resolving [Shubhank Saxena <saxena.shubhank.19@gmail.com>] using commit ID: 080d8802b9554cc7872e7796bc8e977331c9dd9a\n",
      "Creating new hacker object for shubhank-saxena [Shubhank Saxena <saxena.shubhank.19@gmail.com>]\n",
      "Resolving [Songlin Jiang <hollowman@hollowman.ml>] using commit ID: bffe00df74a05d8ae9a536ab215f7e5465283941\n",
      "Creating new hacker object for HollowMan6 [Songlin Jiang <hollowman@hollowman.ml>]\n",
      "Resolving [Hollow Man <hollowman@hollowman.ml>] using commit ID: b66f8737e3d5a386289d91bf5553e217527be5ab\n",
      "Adding alias [Hollow Man <hollowman@hollowman.ml>] for user HollowMan6 for a total of  2\n",
      "Resolving [THANOS SIOURDAKIS <siourdakisthanos@gmail.com>] using commit ID: 2c8a11f072241759922d0877cccc27ff3bb302d7\n",
      "Adding alias [THANOS SIOURDAKIS <siourdakisthanos@gmail.com>] for user weblate for a total of  3\n",
      "Resolving [Guillermo Hernandez <guillermo@querysoft.es>] using commit ID: afdacad160408b84f2ff0dc0ff30c8a55f017bda\n",
      "Creating new hacker object for Oldno7w [Guillermo Hernandez <guillermo@querysoft.es>]\n",
      "Resolving [ilya rahimi <mr.i.rah1385imi@gmail.com>] using commit ID: 42d13be5be42d03d628002d1e3f47fdba19ee4f0\n",
      "Creating new hacker object for ilya-rahimi [ilya rahimi <mr.i.rah1385imi@gmail.com>]\n",
      "Resolving [Jonas Meurer <jonas@freesources.org>] using commit ID: 6c3e46f29e437043b710eca6c6b47089684e90ff\n",
      "Creating new hacker object for mejo- [Jonas Meurer <jonas@freesources.org>]\n",
      "Resolving [nerrehmit <accounts+gitlab@herren.id>] using commit ID: 040472d8c06ee1b74824404492d7b0388b5aaa00\n",
      "Adding alias [nerrehmit <accounts+gitlab@herren.id>] for user msapiro for a total of  3\n",
      "Resolving [Emili Turon <emili.turon@lepton.sk>] using commit ID: 07b1df4901884761752362f3be37c24a3c2f061e\n",
      "Adding alias [Emili Turon <emili.turon@lepton.sk>] for user msapiro for a total of  4\n",
      "Resolving [Pierre Gay <gay.pierre@gmail.com>] using commit ID: 9b36ab610334e8ca3a461402e5b3ed9c4a0e97d3\n",
      "Unable to find author node within JSON formatted result set\n",
      "Resolving [Besnik Bleta <besnik@programeshqip.org>] using commit ID: e7d29a309924b9b08145cc5b069a9cef9aaa5564\n",
      "Creating new hacker object for ujdhesa [Besnik Bleta <besnik@programeshqip.org>]\n",
      "Resolving [ian Vatega <admin@sendenai.com>] using commit ID: d8fe9eaa7118406c40d405cc7ddad7698e27729a\n",
      "Adding alias [ian Vatega <admin@sendenai.com>] for user weblate for a total of  4\n",
      "Resolving [Barry Warsaw <barry@python.org>] using commit ID: 452041035c0287bd91cca4f76c7248b7605f6f9c\n",
      "Creating new hacker object for warsaw [Barry Warsaw <barry@python.org>]\n",
      "Resolving [Emir İşman <6485033-emirisman@users.noreply.gitlab.com>] using commit ID: e5487a7041d593e99029b2d6a5f50f62a330d743\n",
      "Adding alias [Emir İşman <6485033-emirisman@users.noreply.gitlab.com>] for user maxking for a total of  3\n",
      "Resolving [Peter Williams <pwilliam@fredhutch.org>] using commit ID: 39f5bf70939998584f3926bcade490907ff6af8f\n",
      "Creating new hacker object for pwilliamfhcrc [Peter Williams <pwilliam@fredhutch.org>]\n",
      "Resolving [Szylu <chipolade@gmail.com>] using commit ID: b6df4b31cb4a141b7aace9b4366a9c57100657dd\n",
      "Adding alias [Szylu <chipolade@gmail.com>] for user weblate for a total of  5\n",
      "Resolving [Claudio Maradonna <claudio@unitoo.pw>] using commit ID: e4da2d8382251631bf10175d3ed3862450976d11\n",
      "Creating new hacker object for FiloSpaTeam [Claudio Maradonna <claudio@unitoo.pw>]\n",
      "Resolving [akoscomp <nagy.akos@libreoffice.ro>] using commit ID: 0acf9156c996df83b1268878a1a9b9ade0dee8e1\n",
      "Creating new hacker object for akoscomp [akoscomp <nagy.akos@libreoffice.ro>]\n",
      "Resolving [Yaron Shahrabani <sh.yaron@gmail.com>] using commit ID: a0ebf252ac51341a991fed4adb06a6fce3421e10\n",
      "Creating new hacker object for yarons [Yaron Shahrabani <sh.yaron@gmail.com>]\n",
      "Resolving [Paco <pacoc@pangea.org>] using commit ID: 4f9156147f2109ae99449293248a8157edab5a70\n",
      "Adding alias [Paco <pacoc@pangea.org>] for user weblate for a total of  6\n",
      "Resolving [Leandro Navarro <leandro@pangea.org>] using commit ID: 0b0f5dca9b90dc5f4d16a1d90ee59626a7135427\n",
      "Adding alias [Leandro Navarro <leandro@pangea.org>] for user weblate for a total of  7\n",
      "Resolving [kushal kothari <kushalkothari285@gmail.com>] using commit ID: a383e29bd6d523f1df661667fb5d6c23d948c374\n",
      "Creating new hacker object for Kushal-kothari [kushal kothari <kushalkothari285@gmail.com>]\n",
      "Resolving [Juri Grabowski <hosted-weblate@jugra.de>] using commit ID: 1f887ed6a1a5008e7015a8bdab765e178e70b201\n",
      "Adding alias [Juri Grabowski <hosted-weblate@jugra.de>] for user weblate for a total of  8\n",
      "Resolving [phot0n <4653971-phot0n@users.noreply.gitlab.com>] using commit ID: d22a225b68b2fd68dc7ba268c9d57f60369526df\n",
      "Adding alias [phot0n <4653971-phot0n@users.noreply.gitlab.com>] for user maxking for a total of  4\n",
      "Resolving [Jack DuGard <gitlab@sievert-mail.de>] using commit ID: 2d4000a0edecadef05dfe51658ec25cdf984d78d\n",
      "Adding alias [Jack DuGard <gitlab@sievert-mail.de>] for user msapiro for a total of  5\n",
      "Resolving [Daniel Teichmann <daniel.teichmann@das-netzwerkteam.de>] using commit ID: b1b90c9286475b36f7e04845eebb655db53d8ce0\n",
      "Creating new hacker object for dzatoah [Daniel Teichmann <daniel.teichmann@das-netzwerkteam.de>]\n",
      "Resolving [Daniel Teichmann <daniel@teichm-sh.de>] using commit ID: e15007401054d2e65e70dc07d458ab51867466d8\n",
      "Adding alias [Daniel Teichmann <daniel@teichm-sh.de>] for user dzatoah for a total of  2\n",
      "Resolving [Dominic Tubach <gitlab@tubach.net>] using commit ID: 98362e013c7e1bf0fd786b97911210a8807f7b27\n",
      "Adding alias [Dominic Tubach <gitlab@tubach.net>] for user maxking for a total of  5\n",
      "Resolving [Stéphane Parunakian <parunakian.stephane+gitlabcom@gmail.com>] using commit ID: 4a931f1c095d24d3c4630d6d86003453c36096ca\n",
      "Adding alias [Stéphane Parunakian <parunakian.stephane+gitlabcom@gmail.com>] for user maxking for a total of  6\n",
      "Resolving [gene <gene@valimail.com>] using commit ID: bc501bb74b0b26d2e9b2233d8605010921d4b3f3\n",
      "Adding alias [gene <gene@valimail.com>] for user maxking for a total of  7\n",
      "Resolving [ashryaagr <ashryaagr@gmail.com>] using commit ID: 07d18d22f8fc572c7ac4a1c23c3d27bcad667a9c\n",
      "Creating new hacker object for ashryaagr [ashryaagr <ashryaagr@gmail.com>]\n",
      "Resolving [Michael Lutonsky <m@luto.at>] using commit ID: d4b09520659393930948893be4d49273d5b5a980\n",
      "Creating new hacker object for luto [Michael Lutonsky <m@luto.at>]\n",
      "Resolving [Richard Kroegel <rikro@gmx.net>] using commit ID: 127f6f57faba5632c9734291c9f42aca6003b28d\n",
      "Creating new hacker object for rikroe [Richard Kroegel <rikro@gmx.net>]\n",
      "Resolving [Ashrya Agrawal <ashryaagr@gmail.com>] using commit ID: fe3c241689d7bc34c223948c71acb156c146f887\n",
      "Adding alias [Ashrya Agrawal <ashryaagr@gmail.com>] for user ashryaagr for a total of  2\n",
      "Resolving [Prateek Nayak <lelouch.cpp@gmail.com>] using commit ID: 6f3b10c8c23a93130dbb714059e5fa55e201f051\n",
      "Creating new hacker object for Kriyszig [Prateek Nayak <lelouch.cpp@gmail.com>]\n",
      "Resolving [Xiaoxing Ye <ye@xiaoxing.us>] using commit ID: 8e316a86dd3fe089750bb9270170f21bcf61cfad\n",
      "Creating new hacker object for Yexiaoxing [Xiaoxing Ye <ye@xiaoxing.us>]\n",
      "Resolving [Nayan Khanna <f20170636@pilani.bits-pilani.ac.in>] using commit ID: c6d9b549bee6a2038d0b603e4552e181bd93448d\n",
      "Creating new hacker object for nayan2000 [Nayan Khanna <f20170636@pilani.bits-pilani.ac.in>]\n",
      "Resolving [Antoine Beaupré <anarcat@debian.org>] using commit ID: 4eaaae4f9b1b2f1b7da457828349e45e31369b53\n",
      "Creating new hacker object for anarcat [Antoine Beaupré <anarcat@debian.org>]\n",
      "Resolving [Nick Wynja <nick@nickwynja.com>] using commit ID: 4152dbfb658f2636be0c0a4a1f85a3abdbeb7e2b\n",
      "Creating new hacker object for nickwynja [Nick Wynja <nick@nickwynja.com>]\n",
      "Resolving [Bez Thomas <bezthomas@gmail.com>] using commit ID: eea9a18bef587cf1daf51a742087998354e39e4d\n",
      "Creating new hacker object for bezthomas [Bez Thomas <bezthomas@gmail.com>]\n",
      "Resolving [prakashdanish <grafitykoncept@gmail.com>] using commit ID: 179d65e5232a4e15ea0e44053b5072d8d753f63f\n",
      "Creating new hacker object for danishprakash [prakashdanish <grafitykoncept@gmail.com>]\n",
      "Resolving [Jake Scaltreto <jscaltreto@gmail.com>] using commit ID: 0a8408b53dbe4c65d5f45ce975bb2d33d28a6a7a\n",
      "Creating new hacker object for jscaltreto [Jake Scaltreto <jscaltreto@gmail.com>]\n",
      "Resolving [Jan Veen <jan.veen@posteo.de>] using commit ID: 0654a1899759f8343fd1d6cc4b57e162e9db44a6\n",
      "Creating new hacker object for F1rst-Unicorn [Jan Veen <jan.veen@posteo.de>]\n",
      "Resolving [Robin Gloster <mail@glob.in>] using commit ID: d288946bc29c6bb7f85ea3f82a76605899813a9c\n",
      "Creating new hacker object for globin [Robin Gloster <mail@glob.in>]\n",
      "Resolving [Farhaan Bukhsh <farhaan@jnaapti.com>] using commit ID: 3fb62da931b7b0aa90d977dd43c18ed7702efd23\n",
      "Adding alias [Farhaan Bukhsh <farhaan@jnaapti.com>] for user maxking for a total of  8\n",
      "Resolving [Pierre-Elliott Bécue <becue@crans.org>] using commit ID: c4d7548df49ccdd5a090535879a5f0c7652ed497\n",
      "Creating new hacker object for P-EB [Pierre-Elliott Bécue <becue@crans.org>]\n",
      "Resolving [Aurélien Bompard <aurelien@bompard.org>] using commit ID: 8071d4a20cb2231e8f4180901424ce20007d3bd0\n",
      "Creating new hacker object for abompard [Aurélien Bompard <aurelien@bompard.org>]\n",
      "Resolving [Barry Warsaw <bwarsaw@linkedin.com>] using commit ID: 32d3620e6e20e750f1b0c15b3648e4f4e703789c\n",
      "Adding alias [Barry Warsaw <bwarsaw@linkedin.com>] for user warsaw for a total of  2\n",
      "Resolving [Simon Hanna <simon.h4nn4@gmail.com>] using commit ID: 2f230e879c6de1c262744b0bda567d1613c5fffb\n",
      "Creating new hacker object for simonsmiley [Simon Hanna <simon.h4nn4@gmail.com>]\n",
      "Resolving [Rémy Léone <remy.leone@gmail.com>] using commit ID: 3a3dbeb40b0ebed7b6c74fc732721bd71b66b13a\n",
      "Creating new hacker object for remyleone [Rémy Léone <remy.leone@gmail.com>]\n",
      "Resolving [Marcel <gitlab@marehr.dialup.fu-berlin.de>] using commit ID: c851a7d38507a145151a7361042106f220f51ef9\n",
      "Adding alias [Marcel <gitlab@marehr.dialup.fu-berlin.de>] for user warsaw for a total of  3\n",
      "Resolving [J08nY <johny@neuromancer.sk>] using commit ID: c274d8ca000f8ede0dcc3399abd1d35e09355ae6\n",
      "Creating new hacker object for J08nY [J08nY <johny@neuromancer.sk>]\n",
      "Resolving [Stephen J. Turnbull <stephen@xemacs.org>] using commit ID: 674276a3d0404544bd5da74c8a2f2daa8174af40\n",
      "Creating new hacker object for yaseppochi [Stephen J. Turnbull <stephen@xemacs.org>]\n",
      "Resolving [Simon Liebold <simon.liebold@formfall.de>] using commit ID: 2c8d38db987d084c4266656b14d593f7b007ea0c\n",
      "Creating new hacker object for simmis [Simon Liebold <simon.liebold@formfall.de>]\n",
      "Resolving [Terri Oda <terri@toybox.ca>] using commit ID: 0a3e51fb2abae84c9d2ee42c171ccce5b3e67573\n",
      "Creating new hacker object for terriko [Terri Oda <terri@toybox.ca>]\n",
      "Resolving [scott <github@karlin-online.com>] using commit ID: e54203114dd7e2c00b6d11b66ddd81aea3f6d4d4\n",
      "Creating new hacker object for sckarlin [scott <github@karlin-online.com>]\n",
      "Resolving [Tom Briles <tbriles@kavi.com>] using commit ID: 7a584735bd890a736ea2f27d0f488177b52d90b0\n",
      "Adding alias [Tom Briles <tbriles@kavi.com>] for user warsaw for a total of  4\n",
      "Resolving [amitt001 <mail2amit19@gmail.com>] using commit ID: a93b1b431b67714e6ae5b648165b8304eded2651\n",
      "Creating new hacker object for amitt001 [amitt001 <mail2amit19@gmail.com>]\n",
      "Resolving [Amit Tripathi <amit.tripathi@innovaccer.com>] using commit ID: 686e01c717f69fb3ab7918dc933c03cf563258e7\n",
      "Adding alias [Amit Tripathi <amit.tripathi@innovaccer.com>] for user warsaw for a total of  5\n",
      "Resolving [Francesco Ariis <fa-ml@ariis.it>] using commit ID: fd4dd866b540051782c878e7bb115cc5fa4abaa7\n",
      "Creating new hacker object for ffaf1 [Francesco Ariis <fa-ml@ariis.it>]\n",
      "Resolving [Andrew Vereshchagin <broundee@gmail.com>] using commit ID: 78062005ba81be9f8f60107532b2065294e01305\n",
      "Creating new hacker object for broundee [Andrew Vereshchagin <broundee@gmail.com>]\n",
      "Resolving [Aditya <adityadivekar03@gmail.com>] using commit ID: 4836d06c11d81079422073eac66e39c0d03db220\n",
      "Creating new hacker object for adityadivekar03 [Aditya <adityadivekar03@gmail.com>]\n",
      "Resolving [Harshit Bansal <harshitbansal2015@gmail.com>] using commit ID: 17103aae14f53655fd7685a0867724f6420b9282\n",
      "Creating new hacker object for HarshitOnGitHub [Harshit Bansal <harshitbansal2015@gmail.com>]\n",
      "Resolving [Anirudh Dahiya <anirudhdahiya9@gmail.com>] using commit ID: 99b8c0bd9fb4282dc2a692e236ebb7d8747af037\n",
      "Creating new hacker object for anirudhdahiya9 [Anirudh Dahiya <anirudhdahiya9@gmail.com>]\n",
      "Resolving [Gurkirpal <gurkirpal204@gmail.com>] using commit ID: 75941917d8c57b41e2583079f22863326ebf9920\n",
      "Creating new hacker object for gpalsingh [Gurkirpal <gurkirpal204@gmail.com>]\n",
      "Resolving [saurav kumar <saurav24007@gmail.com>] using commit ID: 14dbe7fb4a6b29ce955fa1c8d4c1859c514e8e13\n",
      "Creating new hacker object for Lightyagami1 [saurav kumar <saurav24007@gmail.com>]\n",
      "Resolving [Thomas Schneider <qsuscs@qsuscs.de>] using commit ID: 91a91411f48009a24ccc8951bda081ab61356cc6\n",
      "Creating new hacker object for qsuscs [Thomas Schneider <qsuscs@qsuscs.de>]\n",
      "Resolving [Yashu Seth <yashuseth2503@gmail.com>] using commit ID: e5422f5316335e8cae5dae3965417bb317e057e3\n",
      "Creating new hacker object for yashu-seth [Yashu Seth <yashuseth2503@gmail.com>]\n",
      "Resolving [Barry Warsaw <barry@list.org>] using commit ID: 5bd0f593724f9a696bbefc91ea9c2127b66fa231\n",
      "Unable to find author node within JSON formatted result set\n",
      "Resolving [Abhilash Raj <maxking@angel.angel.in>] using commit ID: d16683ed6be39474ed7285d20c0287f453ff455d\n",
      "Unable to find author node within JSON formatted result set\n",
      "Resolving [Sumana Harihareswara <sumanah@panix.com>] using commit ID: d48b501bb1e1b6970e8cc93e184e4e4da357e1a3\n",
      "Creating new hacker object for brainwane [Sumana Harihareswara <sumanah@panix.com>]\n",
      "Resolving [black-perl ankprashar@gmail.com <>] using commit ID: 4044a657df9b1c332954267b42f8ffe7820e45f0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'login'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 296>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    293\u001b[0m         q\u001b[38;5;241m.\u001b[39madd_commit_id(commit_id, repo)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone loading!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 296\u001b[0m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_aliases\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./aliasMap.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m    299\u001b[0m     out\u001b[38;5;241m.\u001b[39mwrite(json\u001b[38;5;241m.\u001b[39mdumps(q\u001b[38;5;241m.\u001b[39mresolved_alias_map, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mQuery.resolve_aliases\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve_commit(commit_id)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (resp \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_commit_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malias\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mQuery.process_commit_response\u001b[0;34m(self, resp, sha, alias, recursive)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to find author node within JSON formatted result set\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     committer \u001b[38;5;241m=\u001b[39m \u001b[43mcommit_details_block\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (committer \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhackers\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreating new hacker object for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mcommitter\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39malias\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'login'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import hashlib\n",
    "import os\n",
    "from datetime import datetime as datingdays\n",
    "from git import Repo, Git\n",
    "import sys\n",
    "import time\n",
    "project_root_path = '../../..'\n",
    "python_lib_path = project_root_path + '/python/lib'\n",
    "sys.path.append(python_lib_path)\n",
    "#from commit_log_parser import NumstatRequirementSet\n",
    "from pytz import timezone\n",
    "from os.path import exists\n",
    "        \n",
    "def loadCachedURL(url, forceReload = False):\n",
    "    body = None\n",
    "    hl = hashlib.new('sha256')\n",
    "    ba = bytearray(url.encode())\n",
    "    hl.update(ba)\n",
    "    thing = hl.hexdigest()\n",
    "    cachedFileName = './'+thing\n",
    "    loaded = False;\n",
    "    if not forceReload:\n",
    "        try:\n",
    "            with open(cachedFileName, 'r') as f:\n",
    "                body = json.load(f)\n",
    "                f.close()\n",
    "            loaded = True\n",
    "        except EnvironmentError:\n",
    "            pass\n",
    "\n",
    "    if not loaded:\n",
    "        resp = requests.get(url)\n",
    "        if (resp.status_code == 200):\n",
    "            body = resp.json()\n",
    "            with open(cachedFileName, 'w') as f:\n",
    "                f.write(resp.text)\n",
    "                f.close()\n",
    "    return body\n",
    "class Commit:\n",
    "    sha = None\n",
    "    date = None\n",
    "    hacker = None\n",
    "class RepoName:\n",
    "    def key(self):\n",
    "        return self.owner+'/'+self.repo_name\n",
    "    def __init__(self, owner, repo_name):\n",
    "        self.owner = owner\n",
    "        self.repo_name = repo_name\n",
    "    \n",
    "class Hacker:\n",
    "    def toJSON(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, \n",
    "            sort_keys=True, indent=2)    \n",
    "    def __init__(self):\n",
    "        self.user_id = None\n",
    "        self.commits = []\n",
    "        self.aliases = Counter()\n",
    "    def __init__(self, user_id):\n",
    "        self.user_id = user_id;\n",
    "class Repository:\n",
    "    def __init__(self, repo_id, repo_name):\n",
    "        self.repo_id = repo_id\n",
    "        self.repo_name = repo_name\n",
    "class MyCounter:\n",
    "    def __init__(self, init_val):\n",
    "        self.counter = init_val\n",
    "    def __init__(self):\n",
    "        self.__init__(0)\n",
    "    def increment(self):\n",
    "        self.count += 1\n",
    "    def val(self):\n",
    "        return self.counter\n",
    "    \n",
    "# Types of queries:\n",
    "#\n",
    "#  Single query to derive a user ID\n",
    "#  Mass commit log\n",
    "class Query:\n",
    "    def __init__(self):\n",
    "        self.urlPrefix = 'https://api.github.com/search/commits'\n",
    "        self.startDate = datingdays.now(timezone('US/Arizona'))\n",
    "        self.hackers = {}\n",
    "        self.repos = {}\n",
    "        self.aliases = {}\n",
    "        self.resolved_alias_map = {}\n",
    "        self.commit_to_repo_map = {}\n",
    "        self.json_repo_map = {}\n",
    "        self.commit_cache_map = {}\n",
    "        with open('./web3.github.token', 'r') as f:\n",
    "            self.token = f.readline()\n",
    "            self.token = self.token.strip('\\n')\n",
    "            self.headers = {'Authorization': 'token %s' % self.token}\n",
    "    def add_alias(self, alias, commit_key):\n",
    "        if (alias not in self.aliases.keys()):\n",
    "            self.aliases[alias] = []\n",
    "        self.aliases[alias].append(commit_key)\n",
    "    \n",
    "    def reset_last_date(self):\n",
    "        self.startDate = datingdays.now(timezone('US/Arizona'))\n",
    "    def set_last_date(self, date):\n",
    "        new_date = self.startDate\n",
    "        if date.endswith('Z'):\n",
    "            date = date[:len(date)-2]\n",
    "        try:\n",
    "            new_date = datingdays.fromisoformat(date)\n",
    "            if (new_date < self.startDate):\n",
    "    #           Note: GitHub rejected dates with timezones other than \"-07:00\" (like \"+02:00\")\n",
    "    #                 By subtracting the difference (in milliseconds?) we represent the \"US/Arizona\"\n",
    "    #                 version of the author-date pulled from previous results\n",
    "                self.startDate = self.startDate - (self.startDate - new_date)\n",
    "        except:\n",
    "            #Skip a bit, brother.\n",
    "            #Even if this is the very last commit in this set\n",
    "            # it may be repeated at the beginning of the next\n",
    "            # query, but won't cause an endless loop. If it's the last\n",
    "            # commit in the whole set for a particular hacker it will\n",
    "            # still exit the loop due to a < 100 item result set.\n",
    "            pass\n",
    "    def format_user_url(self, user_id):\n",
    "        var = self.urlPrefix+\"?q=author:\"+user_id+'+author-date:<'+self.startDate.isoformat()+'&sort=author-date&order=desc&per_page=100&page=1'\n",
    "        print(var)\n",
    "        return var\n",
    "    def load_hacker_url(self, user_id, recurse_count=1):\n",
    "        retVal = None\n",
    "        resp = requests.get(self.format_user_url(user_id), headers=self.headers)\n",
    "        if (resp.status_code == 200):\n",
    "            retVal = resp.json()\n",
    "        elif (resp.status_code == 403):\n",
    "            print('Rate limit EXCEEDED.  Sleeping for a bit. (recursive_count=', recurse_count,')')\n",
    "            time.sleep(recurse_count * 60)\n",
    "            self.load_hacker_url(user_id, recurse_count+1)\n",
    "        else:\n",
    "            print('Status code returned:', resp.status_code)\n",
    "            req_headers = resp.request.headers\n",
    "            for n in req_headers.keys():\n",
    "                print('\\t', n, req_headers[n])\n",
    "            print(json.dumps(resp.json(), indent=2))\n",
    "        return retVal\n",
    "    def preload_alias_map(self, file_name):\n",
    "        if (exists(file_name)):\n",
    "            with open(file_name, 'r') as af:\n",
    "                self.resolved_alias_map = json.load(af)\n",
    "    def add_commit_id(self, commit_id, repo_name):\n",
    "        self.commit_to_repo_map[commit_id] = repo_name\n",
    "    def format_id_check_url(self, commit_id):\n",
    "        rn = self.commit_to_repo_map[commit_id]\n",
    "        return 'https://api.github.com/repos/'+rn.owner+'/'+rn.repo_name+'/commits/'+commit_id\n",
    "    def retrieve_commit(self, commit_hash):\n",
    "        url = self.format_id_check_url(commit_hash)\n",
    "        resp = requests.get(self.format_id_check_url(commit_hash), headers=self.headers)\n",
    "        if (resp.status_code != 200):\n",
    "            print('ERROR - Status code:', resp.status_code, 'encountered ', url)\n",
    "            return None\n",
    "        else:\n",
    "            return resp\n",
    "    def process_commit_response(self, resp, sha, alias, recursive=False):\n",
    "        j = resp.json()\n",
    "        commit_details_block = j['author']\n",
    "        if (commit_details_block == None):\n",
    "            commit_details_block = j['committer']\n",
    "        if (commit_details_block == None):\n",
    "            if not recursive and len(j['parents']) > 0:\n",
    "                hash = j['parents'][0]['sha']\n",
    "                self.commit_to_repo_map[hash] = self.commit_to_repo_map[sha]\n",
    "                resp = self.retrieve_commit(hash)\n",
    "                if (resp is not None):\n",
    "                    self.process_commit_response(resp, hash, alias, True)\n",
    "            else:\n",
    "                print('Unable to find author node within JSON formatted result set')\n",
    "        else:\n",
    "            committer = commit_details_block['login']\n",
    "            if (committer not in self.hackers.keys()):\n",
    "                print('Creating new hacker object for '+committer+' ['+alias+']')\n",
    "                self.hackers[committer] = []\n",
    "            else:\n",
    "                n = len(self.hackers[committer]) + 1\n",
    "                print('Adding alias ['+alias+'] for user '+committer+' for a total of ', n)\n",
    "            self.hackers[committer].append(alias)\n",
    "            self.resolved_alias_map[alias] = committer\n",
    "        \n",
    "    def resolve_aliases(self):\n",
    "        for alias in self.aliases.keys():\n",
    "            if alias not in self.resolved_alias_map.keys():\n",
    "                commit_id = q.aliases[alias][0]  #Lookup just the first one\n",
    "                print('Resolving ['+alias+'] using commit ID: '+commit_id)\n",
    "                resp = self.retrieve_commit(commit_id)\n",
    "                if (resp != None):\n",
    "                    self.process_commit_response(resp, commit_id, alias)\n",
    "class RepoCounter:\n",
    "    def __init__(self, repo_dict):\n",
    "        self.repo_name = repo_dict['name']\n",
    "        self.repo_full_name = repo_dict['full_name']\n",
    "        owner = repo_dict['owner']\n",
    "        self.owner = owner['login']\n",
    "        self.count = 0\n",
    "    def __init__(self, owner, repo):\n",
    "        self.repo_name = repo\n",
    "        self.repo_full_name = owner+'/'+self.repo_name\n",
    "        self.owner = owner\n",
    "        self.count = 0\n",
    "    def add_one(self):\n",
    "        self.count += 1\n",
    "        \n",
    "    def key(self):\n",
    "        return self.repo_full_name\n",
    "\n",
    "if 0 == 1:    \n",
    "    with open('./repo_classes.json', \"r\") as r:\n",
    "        array = json.load(r)\n",
    "else:\n",
    "    array = {}\n",
    "    with open('./new_repo.log', 'r') as r:\n",
    "        for l in r.readlines():\n",
    "            key = l[:-1] #Strip off carriage return\n",
    "            s = key.split('/')\n",
    "            array[key] = {'owner':s[0], 'repo_name':s[1], 'repo_full_name':key, 'count':0}\n",
    "\n",
    "q = Query()\n",
    "\n",
    "aliasMapName = './aliasMap.json' \n",
    "if exists(aliasMapName):\n",
    "    with open(aliasMapName, 'r') as r:\n",
    "        q.resolved_alias_map = json.load(r)\n",
    "if exists('./hackers.json'):\n",
    "    with open('./hackers.json', 'r') as r:\n",
    "        q.hackers = json.load(r)\n",
    "elif q.resolved_alias_map is not None and len(q.resolved_alias_map) > 0:\n",
    "    for alias in q.resolved_alias_map:\n",
    "        user_id = q.resolved_alias_map[alias]\n",
    "        if user_id not in q.hackers.keys():\n",
    "            q.hackers[user_id] = []\n",
    "        q.hackers[user_id].append(alias) \n",
    "    \n",
    "for n in array.values():\n",
    "    owner = n['owner']\n",
    "    repo_name = n['repo_name']\n",
    "    repo = RepoName(owner, repo_name)\n",
    "    print('Processing', owner, repo_name)\n",
    "    repo_base_dir = './repos'\n",
    "    result_base_dir = './results'\n",
    "    repo_path = repo_base_dir+'/'+repo.key()\n",
    "    result_path = result_base_dir+'/'+repo.key()\n",
    "    json_stats_file_name = result_path+'/commit_stat_log.json'\n",
    "#    stat_req_set = StatRequirementSet()\n",
    "    numstat_req_set = NumstatRequirementSet()\n",
    "    last_date = datingdays.fromisoformat('1972-12-26T03:23:01.123456-07:00')\n",
    "\n",
    "    if (os.path.isdir(repo_base_dir) == False):\n",
    "        print('######### Cannot find '+repo_base_dir+'  Creating it!')\n",
    "        os.makedirs(repo_base_dir)\n",
    "    if os.path.isdir(result_base_dir) == False:\n",
    "        print('Cannot find',result_base_dir,'Creating it!')\n",
    "        os.makedirs(result_base_dir)\n",
    "    if os.path.isdir(result_base_dir+'/'+owner) == False:\n",
    "        os.makedirs(result_base_dir+'/'+owner)\n",
    "    if os.path.isdir(result_base_dir+'/'+owner+'/'+repo_name) == False:\n",
    "        os.makedirs(result_base_dir+'/'+owner+'/'+repo_name)\n",
    "    if (os.path.isdir(repo_base_dir+\"/\"+owner) == False):\n",
    "        os.makedirs(repo_base_dir+\"/\"+owner)\n",
    "    url = 'https://github.com/'+owner+'/'+repo_name+'.git'\n",
    "    if (os.path.isdir(repo_path) == False):\n",
    "        Repo.clone_from(url, repo_path)\n",
    "    else:\n",
    "        rp = Repo(repo_path)\n",
    "        remote = rp.remote()\n",
    "        remote.pull()\n",
    "        if exists(json_stats_file_name+'NOT NOT NOT NOT NOT'):\n",
    "            with open(json_stats_file_name) as j:\n",
    "                numstat_req_set.resultArray = json.load(j)\n",
    "            for item in numstat_req_set.resultArray:\n",
    "                q.commit_cache_map[item['commit']] = item\n",
    "# Add call to rep.log('-1') to get the date from the latest change\n",
    "#  If that date is less than the date on the cached stats file\n",
    "#  then skip this one by loading the previous stats file.\n",
    "    print('Generating Stats for '+repo_path)\n",
    "    rep = Git(repo_path)\n",
    "    stat = rep.log('--numstat')\n",
    "\n",
    "    numstat_req_set.processDocument(stat)\n",
    "    q.repos[repo.owner+'/'+repo.repo_name] = numstat_req_set.resultArray.copy()\n",
    "    \n",
    "    if repo.owner not in q.json_repo_map.keys():\n",
    "        q.json_repo_map[repo.owner] = {}\n",
    "    q.json_repo_map[repo.owner][repo.repo_name] = q.repos[repo.key()]\n",
    "    with open(json_stats_file_name, 'w') as out:\n",
    "        out.write(json.dumps(numstat_req_set.resultArray, indent=2))\n",
    "    for rae in numstat_req_set.resultArray:\n",
    "        commit_id = rae['commit']\n",
    "        alias = rae['Author']\n",
    "        q.add_alias(alias, commit_id)\n",
    "        q.add_commit_id(commit_id, repo)\n",
    "        \n",
    "print('Done loading!')\n",
    "q.resolve_aliases()\n",
    "\n",
    "with open('./aliasMap.json', 'w') as out:\n",
    "    out.write(json.dumps(q.resolved_alias_map, indent=2))\n",
    "    \n",
    "with open('./new_repos.json', 'w') as out:\n",
    "    out.write(json.dumps(q.repos, indent=2))\n",
    "with open('./hackers.json', 'w') as out:\n",
    "    out.write(json.dumps(q.hackers, indent=2))\n",
    "    \n",
    "for alias in q.aliases.keys():\n",
    "    v = q.aliases[alias]\n",
    "    print('Alias ', alias, ' has ', len(v), ' commits')\n",
    "    \n",
    "print('How many hackers?', len(q.hackers))    \n",
    "repo_counter = {}\n",
    "call_count = 0\n",
    "if 1 == 0:\n",
    "    with open('./new_repo.log', 'w') as new_repo_log:\n",
    "        for hacker in q.hackers:\n",
    "            done = False\n",
    "            q.reset_last_date()\n",
    "            last_count = -1\n",
    "            while not done:\n",
    "                body = q.load_hacker_url(hacker)\n",
    "                call_count += 1\n",
    "                if call_count % 25 == 0:\n",
    "                    print(call_count, 'rest API calls made')\n",
    "\n",
    "                if (body == None):\n",
    "                    print('Unable to load JSON')\n",
    "                    done = True\n",
    "                else:\n",
    "                    total_count = body['total_count']\n",
    "                    if (total_count == last_count):\n",
    "                        print('Identical result set found.  Moving on.', total_count, last_count)\n",
    "                        done = True\n",
    "                    else:\n",
    "                        print(total_count, 'remaining commits for user', hacker)\n",
    "                    last_count = total_count\n",
    "                    if total_count > 20000:\n",
    "                        print('Yikes!', total_count, ' seems like a few too many')\n",
    "                        done = True\n",
    "                    incomplete_results = body['incomplete_results']\n",
    "        #            print(total_count)\n",
    "        #            print(incomplete_results)\n",
    "                    array = body['items'];\n",
    "                    if (array == None or len(array) < 1):\n",
    "                        done = True\n",
    "                    else:\n",
    "                        for n in array:\n",
    "                            repo = n['repository']\n",
    "                            repo_full_name = repo['full_name']\n",
    "                            counter = None\n",
    "                            if repo_full_name not in repo_counter:\n",
    "                                counter = RepoCounter(repo)\n",
    "                                repo_counter[repo_full_name] = counter\n",
    "                                print('New repo found!', repo_full_name)\n",
    "                                new_repo_log.write(repo_full_name+'\\n')\n",
    "                            else:\n",
    "                                counter = repo_counter[repo_full_name]\n",
    "                            counter.add_one()\n",
    "\n",
    "                            commit = n['commit']\n",
    "                            comAuth = commit['author']\n",
    "                            q.set_last_date(comAuth['date'])\n",
    "                        if (total_count < 100 and incomplete_results == False):\n",
    "                            done = True\n",
    "\n",
    "with open('./hackers.json', 'w') as out:\n",
    "    out.write(json.dumps(q.hackers, indent=2))\n",
    "        \n",
    "with open('./repo_classes.json', 'w') as out:\n",
    "    out.write(json.dumps(repo_counter,default=lambda o: o.__dict__, \n",
    "            sort_keys=True,indent=2))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b642d46-ecf8-468e-b4a0-a82c3521d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as datingdays\n",
    "fmt = '%Y-%m-%dT%H:%M:%S.%f%z'\n",
    "t = '2020-01-28T15:47:53.000+01:00'\n",
    "rslt = datingdays.strptime(t, fmt)\n",
    "print(rslt)\n",
    "print(rslt.strftime(fmt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d4809-4dd5-40c5-b85a-67b31a391e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from pytz import timezone\n",
    "d = dt.fromisoformat('2022-04-11T19:14:33.000+02:00')\n",
    "\n",
    "#az = timezone('US/Arizona')\n",
    "#d2 = az.localize(d, is_dst=False)\n",
    "#d2              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ba6e9-d798-4d66-85e8-8d1cd189da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "# Given timestamp in string\n",
    "time_str = '24/7/2021 11:13:08.230010'\n",
    "date_format_str = '%d/%m/%Y %H:%M:%S.%f'\n",
    "# create datetime object from timestamp string\n",
    "given_time = datetime.strptime(time_str, date_format_str)\n",
    "print('Given Time: ', given_time)\n",
    "n = 2\n",
    "# Subtract 2 hours from datetime object\n",
    "final_time = given_time - timedelta(hours=n)\n",
    "print('Final Time (2 hours ahead of given time ): ', final_time)\n",
    "# Convert datetime object to string in specific format \n",
    "final_time_str = final_time.strftime('%d/%m/%Y %H:%M:%S.%f')\n",
    "print('Final Time as string object: ', final_time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d2a1dc-6ebf-40fa-8506-e26bf360fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.github.com/search/commit/fb5f372203f70cc7580f8e9806c00405524649d7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bdd465-317d-46c2-8aa4-a62cfc94d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print('Getting started')\n",
    "rev = {}\n",
    "with open('./aliasMap.json', \"r\") as r:\n",
    "    body = json.load(r)\n",
    "    for k in body.keys():\n",
    "        v = body[k]\n",
    "        if v not in rev.keys():\n",
    "            rev[v] = []\n",
    "        rev[v].append(k)\n",
    "with open('./idToAliasMap.json', 'w') as w:\n",
    "    w.write(json.dumps(rev, indent=2))    \n",
    "print('Done!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e76493-e5b4-45db-bda8-5f2a18bdac40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
