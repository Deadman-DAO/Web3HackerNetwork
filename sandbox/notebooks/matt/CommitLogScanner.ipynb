{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d0aa4b0-6209-4dcb-80ad-e8ce3e871081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=8, micro=10, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f4fff7-d839-4de2-9bd0-794ebe51e953",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hack window for playing with ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4589c124-9525-40c7-8915-1d3576de4048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "fi = FileInfo('ext')\n",
    "fi.textLineCount = 1644\n",
    "plusCount = 29\n",
    "minusCount = 0\n",
    "n = plusCount * 1.0\n",
    "print(n)\n",
    "n = n / (plusCount + minusCount)\n",
    "print(n)\n",
    "print(fi.textLineCount)\n",
    "n = n * (1.0 * fi.textLineCount)\n",
    "print(n)\n",
    "fi.insertCount = int(fi.textLineCount * ((plusCount * 1.0) / (plusCount + minusCount)))\n",
    "fi.deleteCount = fi.textLineCount - fi.insertCount\n",
    "print(fi.insertCount, ',', fi.deleteCount)\n",
    "'''\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9851307c-57a7-4b85-a43b-3e8b7a02c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def introspect(obj):\n",
    "  for func in [type, id, dir, vars, callable]:\n",
    "        print(\"%s(%s):\\t\\t%s\" % (func.__name__, introspect.__code__.co_varnames[0], func(obj)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c620fe24-371a-49a7-b601-5baf58d2ee46",
   "metadata": {},
   "source": [
    "### Main Entry Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb1f0d-afbb-43df-a77f-095836a506da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206 files\n",
      "Processing /home/matt/Projects/Web3HackerNetwork/sandbox/notebooks/matt/results/polkadot-js/api/commit_stat_log.json\n",
      "https://github.com/polkadot-js/api\n",
      "Processed 6394 records for polkadot-js api\n",
      "Processing /home/matt/Projects/Web3HackerNetwork/sandbox/notebooks/matt/results/ApeWorX/ape/commit_stat_log.json\n",
      "https://github.com/ApeWorX/ape\n",
      "Processed 370 records for ApeWorX ape\n",
      "Processing /home/matt/Projects/Web3HackerNetwork/sandbox/notebooks/matt/results/mozilla/glam/commit_stat_log.json\n",
      "https://github.com/mozilla/glam\n",
      "Processed 961 records for mozilla glam\n",
      "Processing /home/matt/Projects/Web3HackerNetwork/sandbox/notebooks/matt/results/mozilla/zamboni/commit_stat_log.json\n",
      "https://github.com/mozilla/zamboni\n",
      "Processed 21570 records for mozilla zamboni\n",
      "Processing /home/matt/Projects/Web3HackerNetwork/sandbox/notebooks/matt/results/Biohazard1976/pip/commit_stat_log.json\n",
      "https://github.com/Biohazard1976/pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "project_root_path = '../../..'\n",
    "python_lib_path = project_root_path + '/python/lib'\n",
    "sys.path.append(python_lib_path)\n",
    "import commit_log_parser\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import mariadb\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime as datingdays\n",
    "\n",
    "mydb = mariadb.connect(\n",
    "    host='localhost',\n",
    "    user='w3hacknet',\n",
    "    password='aSecret42',\n",
    "    database='w3hacknet',\n",
    "    autocommit=True\n",
    ")\n",
    "\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "def insert_result(array, owner, repo_name):\n",
    "    '''\n",
    "    CREATE PROCEDURE w3hacknet.InsertCommit(owner_id varchar(128), repo_name varchar(128), commit_id char(40), author_hash char(32), author_alias varchar(128), date datetime, orig_timezone varchar(16))\n",
    "    '''\n",
    "    for n in array:\n",
    "        cursor.callproc('w3hacknet.InsertCommit', \n",
    "                        (owner,\n",
    "                         repo_name, \n",
    "                         n['commit'], \n",
    "                         hashlib.md5(n['Author'].encode('utf-8')).hexdigest(),\n",
    "                         n['Author'],\n",
    "                         datingdays.fromisoformat(n['Date']),\n",
    "                         n['orig_timezone'],\n",
    "                         json.dumps(n['fileTypes']) ) )\n",
    "    print('Processed',len(array),'records for', owner, repo_name)\n",
    "                         \n",
    "                         \n",
    "\n",
    "fileList = []\n",
    "commit_log_parser.addFiles(fileList, '/home/matt/Projects/Web3HackerNetwork/sandbox/notebooks/matt/results');\n",
    "print('Found '+str(len(fileList))+' files');\n",
    "for n in fileList:\n",
    "    if n.fileName == 'commit_stat_log.json':\n",
    "        print('Processing', n.fullyQualified)\n",
    "        p = Path(n.fullyQualified)\n",
    "        print('https://github.com/'+p.parent.parent.name+'/'+p.parent.name)\n",
    "        with open(n.fullyQualified, 'r') as r:\n",
    "            insert_result(json.load(r), p.parent.parent.name, p.parent.name)\n",
    "        #introspect(p.parent)\n",
    "'''\n",
    "root = '/home/matt/Projects/Web3HackerNetwork/data/samples'\n",
    "log = open(root+'/commitScan.log', 'w')\n",
    "for fileClass in fileList:\n",
    "    linecount = 0\n",
    "    \n",
    "    if (fileClass.fileName != 'commit-stat.log'):\n",
    "        #print('Skipping '+fileClass.fileName)\n",
    "        a = 0\n",
    "    else:\n",
    "        fq = fileClass.fullyQualified\n",
    "        print('Processing ',fq)\n",
    "        tsvFileName = str(fq)+'.json'\n",
    "        result = open(tsvFileName, 'w')\n",
    "\n",
    "        reqSet = StatRequirementSet()\n",
    "\n",
    "        with open(str(fileClass.fullyQualified), 'r') as file:\n",
    "            log.write('Reading file: '+fileClass.fullyQualified+'\\n')\n",
    "\n",
    "            for line in file:\n",
    "                linecount += 1\n",
    "                reqSet.testline(line);\n",
    "            file.close()\n",
    "            \n",
    "        result.write(json.dumps(reqSet.resultArray, indent=2))\n",
    "        reqSet.resultArray.clear()\n",
    "        nBytes = result.tell()\n",
    "        result.close();\n",
    "        if (nBytes < 1):\n",
    "            os.remove(tsvFileName)\n",
    "\n",
    "\n",
    "        print(str(fileClass.fileName)+' : '+str(linecount)+' lines')\n",
    "'''\n",
    "print('All done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "401d92ba-654e-454b-aad9-9a435ae04684",
   "metadata": {},
   "outputs": [],
   "source": [
    "    rslt = mydb.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de3034f-ae3b-4f10-a3bf-589c84855b2e",
   "metadata": {},
   "source": [
    "### Testing time-zone aware date comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b242f27-9316-497b-b5e2-552b54288e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as datingdays\n",
    "from pytz import timezone\n",
    "last_date = datingdays.fromisoformat('1972-12-26T03:23:01.123456-07:00')\n",
    "nowness = datingdays.now(timezone('US/Arizona'))\n",
    "print(nowness - last_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f74fc0a-4fa0-49d8-80ac-4f6e288fc467",
   "metadata": {},
   "source": [
    "### Clone/Pull all of the repositories listed in input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d32f41-41d0-4681-bd25-0af21df2c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from git import Repo, Git\n",
    "\n",
    "with open('./new_repo.log', 'r') as r:\n",
    "    for l in r.readlines():\n",
    "        key = l[:-1] #Strip off carriage return\n",
    "        s = key.split('/')\n",
    "        owner = s[0]\n",
    "        repo_name = s[1]\n",
    "        full_name = key\n",
    "        print('Processing', owner, repo_name)\n",
    "        repo_base_dir = './repos'\n",
    "        repo_path = repo_base_dir+'/'+key\n",
    "\n",
    "        if (os.path.isdir(repo_base_dir) == False):\n",
    "            print('######### Cannot find '+repo_base_dir+'  Creating it!')\n",
    "            os.makedirs(repo_base_dir)\n",
    "        if (os.path.isdir(repo_base_dir+\"/\"+owner) == False):\n",
    "            os.makedirs(repo_base_dir+\"/\"+owner)\n",
    "        url = 'https://github.com/'+owner+'/'+repo_name+'.git'\n",
    "        if (os.path.isdir(repo_path) == False):\n",
    "            Repo.clone_from(url, repo_path)\n",
    "        else:\n",
    "            rp = Repo(repo_path)\n",
    "            remote = rp.remote()\n",
    "            remote.pull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4f6ed-3371-46db-9752-da2ff539e397",
   "metadata": {},
   "source": [
    "### Better way of running git and gather statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812f949-a9c6-4ea5-b7e2-561b0ae44b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import json\n",
    "from datetime import datetime as datingdays\n",
    "from pytz import timezone\n",
    "from pydriller import Repository\n",
    "import sys\n",
    "project_root_path = '../../..'\n",
    "python_lib_path = project_root_path + '/python/lib'\n",
    "sys.path.append(python_lib_path)\n",
    "import commit_log_parser\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "last_date = datingdays.fromisoformat('1972-12-26T03:23:01.123456-07:00')\n",
    "\n",
    "def introspect(obj):\n",
    "  for func in [type, id, dir, vars, callable]:\n",
    "        print(\"%s(%s):\\t\\t%s\" % (func.__name__, introspect.__code__.co_varnames[0], func(obj)))\n",
    "\n",
    "class CommitStats():\n",
    "    def toJSON(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, \n",
    "            sort_keys=True, indent=2)    \n",
    "    def __init__(self):\n",
    "        self.commit = ''\n",
    "        self.commit_timestamp = ''\n",
    "        self.author_name = ''\n",
    "        self.author_email = ''\n",
    "        self.file_stats_dic = {}\n",
    "    def determine_file_type(self, file_name):\n",
    "        retVal = 'blank'\n",
    "        if file_name is not None and len(file_name) > 0:\n",
    "            s = file_name.split('.')\n",
    "            if len(s) > 1:\n",
    "                retVal = s[len(s)-1]\n",
    "        return retVal\n",
    "    def process_commit(self, c):\n",
    "        statPerf = 0\n",
    "        base = datingdays.now().timestamp()\n",
    "        if c.author is None or c.author.name is None or c.author.email is None:\n",
    "            print('No author found in commit: ', c.hexsha)\n",
    "            if c.parents is not None and len(c.parents) > 0:\n",
    "                print('Trying recursive for ', c.parents[0].hexsha)\n",
    "                process_commit(c.parents[0])\n",
    "        else:\n",
    "            self.commit = c.hash\n",
    "            self.author_name = c.author.name\n",
    "            self.author_email = c.author.email\n",
    "            self.commit_timestamp = datingdays.isoformat(c.committer_date)\n",
    "            for stat in c.modified_files:\n",
    "                file_type = self.determine_file_type(stat.filename)\n",
    "                if file_type not in self.file_stats_dic.keys():\n",
    "                    self.file_stats_dic[file_type] = {}\n",
    "                    self.file_stats_dic[file_type]['file_count'] = 0\n",
    "                    self.file_stats_dic[file_type]['insert_count'] = 0\n",
    "                    self.file_stats_dic[file_type]['delete_count'] = 0\n",
    "                self.file_stats_dic[file_type]['file_count'] += 1\n",
    "                i = stat.added_lines\n",
    "                d = stat.deleted_lines\n",
    "                if i == 0 and d == 0:\n",
    "                    pass\n",
    "#                    print('Working dir? '+repo.working_dir)\n",
    "                else:\n",
    "                    self.file_stats_dic[file_type]['insert_count'] += i\n",
    "                    self.file_stats_dic[file_type]['delete_count'] += d\n",
    "                \n",
    "\n",
    "file_dic = {}\n",
    "user_map = {}\n",
    "print(datingdays.now())\n",
    "master_map = {}\n",
    "with open('./new_repo.log', 'r') as r:\n",
    "    for l in r.readlines():\n",
    "        base_map = {}\n",
    "        key = l[:-1] #Strip off carriage return\n",
    "        s = key.split('/')\n",
    "        owner = s[0]\n",
    "        repo_name = s[1]\n",
    "        full_name = key\n",
    "        repo_base_dir = './repos'\n",
    "        repo_path = repo_base_dir+'/'+key\n",
    "        \n",
    "        cnt = 0\n",
    "        for commit in Repository(repo_path).traverse_commits():\n",
    "            cnt += 1\n",
    "            if cnt % 100 == 0:\n",
    "                print(cnt,'Processing', owner, repo_name, commit.author.name, commit.author_date, commit.hash)\n",
    "            obj = CommitStats()\n",
    "            obj.process_commit(commit)\n",
    "            base_map[obj.commit] = obj\n",
    "        print(cnt, 'commits processed total')\n",
    "        with open(repo_base_dir+'/commit_stat_log.json', 'w') as w:\n",
    "            w.write(json.dumps(base_map, default=lambda o: o.__dict__, sort_keys=True, indent=2))\n",
    "        master_map[key] = base_map\n",
    "        \n",
    "with open('./master_commit_stat_log.json', 'w') as w:\n",
    "    w.write(json.dumps(master_map, default=lambda o: o.__dict__, sort_keys=True, indent=2))\n",
    "    \n",
    "'''    \n",
    "    d = c.committed_datetime\n",
    "    print(d)\n",
    "    if d > last_date:\n",
    "        last_date = d;\n",
    "#    print(c.stats.total)\n",
    "    for f in c.stats.files:\n",
    "        stat = c.stats.files[f]\n",
    "        print(f, stat['insertions'], stat['deletions'], stat['lines'])\n",
    "    \n",
    "print('Latest date: ', last_date)  \n",
    "'''\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf1b4d1-2e58-4ab5-b00e-a2df14547aa5",
   "metadata": {},
   "source": [
    "### Multi-threaded status logger (experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1254974d-c4bb-4db0-8aea-37fc88c3393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import logging\n",
    "class Thing():\n",
    "    def __init__(self):\n",
    "        format = \"%(asctime)s: %(message)s\"\n",
    "        logging.basicConfig(format=format, level=logging.INFO,\n",
    "                            datefmt=\"%H:%M:%S\")        \n",
    "        self.thread = threading.Thread(target=self.monitor, daemon=True)\n",
    "        self.thread.start()\n",
    "        self.running = True\n",
    "    def stop(self):\n",
    "        self.running = false\n",
    "        self.thread.interrupt()\n",
    "    def monitor(self):\n",
    "        print('Made it here')\n",
    "        while self.running:\n",
    "            time.sleep(5)\n",
    "            logging.info(\"Still here monitoring\")\n",
    "            \n",
    "t = Thing()\n",
    "print(\"Waiting around to see if background thread works\")\n",
    "print(t.thread)\n",
    "time.sleep(30)\n",
    "t.running = False\n",
    "t.join()\n",
    "print(\"Leaving...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42236563-4c0f-4bf7-aab4-31e012c47df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
